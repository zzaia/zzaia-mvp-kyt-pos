{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected Dataset: Elliptic Data Set\n",
    "\n",
    "**Selection Date**: 2025-08-29  \n",
    "**Selected from**: dataset-exploration-risk-scoring-research.md  \n",
    "**Rank**: #1 out of 10 evaluated datasets  \n",
    "**Suitability Score**: 92/100  \n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "### **Elliptic Data Set**\n",
    "- **Source Platform**: Kaggle\n",
    "- **Direct URL**: https://www.kaggle.com/datasets/ellipticco/elliptic-data-set\n",
    "- **Dataset Size**: 200,000 transactions ï¿½ 166 features, ~6GB\n",
    "- **Problem Relevance**: High - Bitcoin illicit transaction classification\n",
    "- **Data Quality**: Excellent - professionally curated by Elliptic Co.\n",
    "- **License Type**: Open (with attribution requirements)\n",
    "- **Last Updated**: 2019 (stable reference dataset)\n",
    "- **Preprocessing Needs**: Minimal - ready for ML training\n",
    "\n",
    "## Key Features and Structure\n",
    "\n",
    "### Feature Categories\n",
    "- **Local Features**: 94 transaction-specific features\n",
    "- **Aggregate Features**: 72 neighborhood/graph-based features  \n",
    "- **Total Features**: 166 feature dimensions\n",
    "- **Temporal Component**: Time step information included\n",
    "- **Labels**: Binary classification (illicit/licit)\n",
    "\n",
    "### Specific Features Include:\n",
    "- Transaction fees\n",
    "- Input/output volumes  \n",
    "- Neighbor aggregates\n",
    "- Time steps\n",
    "- BTC amounts\n",
    "- Graph topology metrics\n",
    "- Wallet clustering information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5e9b9c",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "Install and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hlbu6h0o8wc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed8199",
   "metadata": {},
   "source": [
    "### Download the original dataset\n",
    "\n",
    "Create the dataset directory and download the original data from source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cfdafda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/ellipticco/elliptic-data-set\n",
      "  - elliptic_bitcoin_dataset (0.00 MB)\n"
     ]
    }
   ],
   "source": [
    "original_dir = Path(\"../original\")\n",
    "specific_dir = original_dir / \"elliptic_bitcoin_dataset\"\n",
    "if(specific_dir.exists() and any(specific_dir.iterdir())):\n",
    "    print(f\"Dataset already exists in {original_dir}, skipping download.\")\n",
    "else:\n",
    "    original_dir.mkdir(exist_ok=True)\n",
    "    dataset_name = \"ellipticco/elliptic-data-set\"\n",
    "    kaggle.api.dataset_download_files(\n",
    "        dataset_name, \n",
    "        path=str(original_dir), \n",
    "        unzip=True\n",
    "    )\n",
    "    \n",
    "    downloaded_files = list(original_dir.glob(\"*\"))\n",
    "    for file_path in downloaded_files:\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024) if file_path.is_file() else 0\n",
    "        print(f\"  - {file_path.name} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0ea36",
   "metadata": {},
   "source": [
    "## Dataset Visualization\n",
    "\n",
    "Let's visualize the dataset in order to check which pre-process to apply:\n",
    "1. Missing Values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e078b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Dataset Summary:\n",
      "  - Features: 203,769 transactions Ã— 167 features\n",
      "           0  1         2         3\n",
      "0  230425980  1 -0.171469 -0.184668\n",
      "1    5530458  1 -0.171484 -0.184668\n",
      "2  232022460  1 -0.172107 -0.184668\n",
      "3  232438397  1  0.163054  1.963790\n",
      "4  230460314  1  1.011523 -0.081127\n",
      "5  230459870  1  0.961040 -0.081127\n",
      "6  230333930  1 -0.171264 -0.184668\n",
      "7  230595899  1 -0.171755 -0.184668\n",
      "8  232013274  1 -0.123127 -0.184668\n",
      "9  232029206  1 -0.005027  0.578941\n",
      "  - Classes: 203,769 labeled transactions\n",
      "        txId    class\n",
      "0  230425980  unknown\n",
      "1    5530458  unknown\n",
      "2  232022460  unknown\n",
      "3  232438397        2\n",
      "4  230460314  unknown\n",
      "5  230459870  unknown\n",
      "6  230333930  unknown\n",
      "7  230595899  unknown\n",
      "8  232013274  unknown\n",
      "9  232029206        2\n",
      "  - Edges: 234,355 transaction relationships\n",
      "       txId1      txId2\n",
      "0  230425980    5530458\n",
      "1  232022460  232438397\n",
      "2  230460314  230459870\n",
      "3  230333930  230595899\n",
      "4  232013274  232029206\n",
      "5  232344069   27553029\n",
      "6   36411953  230405052\n",
      "7   34194980    5529846\n",
      "8    3881097  232457116\n",
      "9  230409257   32877982\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_file = specific_dir / \"elliptic_txs_features.csv\"\n",
    "if features_file.exists(): df_features = pd.read_csv(features_file, header=None)\n",
    "else: df_features = pd.DataFrame()\n",
    "classes_file = specific_dir / \"elliptic_txs_classes.csv\"\n",
    "if classes_file.exists(): df_classes = pd.read_csv(classes_file)\n",
    "else: df_classes = pd.DataFrame()\n",
    "edges_file = specific_dir / \"elliptic_txs_edgelist.csv\"\n",
    "if edges_file.exists(): df_edges = pd.read_csv(edges_file)\n",
    "else: df_edges = pd.DataFrame()\n",
    "\n",
    "# Summary of all datasets\n",
    "print(f\"\\nðŸ“Š Dataset Summary:\")\n",
    "print(f\"  - Features: {df_features.shape[0]:,} transactions Ã— {df_features.shape[1]} features\")\n",
    "print(df_features.iloc[:, :4].head(10)) \n",
    "print(f\"  - Classes: {df_classes.shape[0]:,} labeled transactions\")\n",
    "print(df_classes.head(10))\n",
    "print(f\"  - Edges: {df_edges.shape[0]:,} transaction relationships\")\n",
    "print(df_edges.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a0b2f",
   "metadata": {},
   "source": [
    "## Apply pre-processing transformation \n",
    "Let's apply the feature transformation to normalize the data:\n",
    " 1. Feature Standard Scaling: ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0cf9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
