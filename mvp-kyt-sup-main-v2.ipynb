{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVP Know Your Transaction (KYT) - Real-Time Transaction Risk Scoring Engine\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This notebook presents a comprehensive implementation of a Real-Time Transaction Risk Scoring Engine for Anti-Money Laundering (AML) compliance in cryptocurrency transactions. The project addresses the critical need for sub-second risk assessment of Bitcoin transactions by combining traditional AML indicators with blockchain-specific risk factors.\n",
    "\n",
    "### Domain Context: Financial AML for Transactions\n",
    "\n",
    "#### Core Domain Definition\n",
    "Anti-Money Laundering (AML) for transactions encompasses the comprehensive framework of laws, regulations, procedures, and technological solutions designed to prevent criminals from disguising illegally obtained funds as legitimate income through the global financial system. This domain includes detection, prevention, and reporting of money laundering, terrorist financing, tax evasion, market manipulation, and misuse of public funds.\n",
    "\n",
    "### Problem Definition: Real-Time Transaction Risk Classification Engine\n",
    "\n",
    "#### Problem Statement\n",
    "Develop a system that assigns risk classifications to cryptocurrency transactions in real-time, integrating traditional AML indicators with blockchain-specific risk factors including wallet clustering, transaction graph analysis, and counterparty reputation scoring.\n",
    "\n",
    "#### Technical Requirements\n",
    "- **Problem Type**: Classification \n",
    "- **Processing Speed**: Sub-second analysis for high-frequency transactions\n",
    "- **Difficulty Level**: High - requires complex multi-dimensional data processing\n",
    "- **Output Format**: Risk binary classification (illicit/licit)\n",
    "\n",
    "#### Data Landscape\n",
    "The system processes multiple data dimensions:\n",
    "- Transaction metadata (amounts, timestamps, fees)\n",
    "- Wallet addresses and clustering information\n",
    "- Transaction graph relationships and network topology\n",
    "- Counterparty databases and reputation scores\n",
    "- Sanctions lists and regulatory databases\n",
    "- Temporal patterns and behavioral baselines\n",
    "\n",
    "### References\n",
    "\n",
    "This notebook implementation is based on the comprehensive research and analysis conducted during the project development phase. The following reference documents were used in the composition of this initial description:\n",
    "\n",
    "- **Domain Research**: [current-domain.md](domains/current-domain.md) - Contains detailed market analysis, regulatory framework research, and commercial viability assessment for the Financial AML domain\n",
    "- **Problem Analysis**: [current-problem.md](problems/current-problem.md) - Provides comprehensive problem refinement, technical requirements analysis, and solution approach evaluation\n",
    "- **Dataset Evaluation**: [current-dataset.md](datasets/current-dataset.md) - Documents dataset selection criteria, suitability scoring, and detailed feature analysis for the Elliptic dataset\n",
    "- **Dataset Analysis & Preprocessing**: [dataset-analysis-and-preprocessing.ipynb](datasets/scripts/dataset-analysis-and-preprocessing.ipynb) - Comprehensive Jupyter notebook containing Elliptic dataset download, exploratory data analysis, feature engineering, preprocessing pipeline, and ML preparation steps\n",
    "\n",
    "These reference documents contain the foundational research that informed the technical approach, feature engineering strategy, and implementation decisions reflected in this notebook.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook serves as the primary entry point for the MVP KYT implementation, providing both technical implementation and business context for real-time cryptocurrency transaction risk assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "Comprehensive import of all required libraries for machine learning procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "# Suppress all warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "#optuna.logging.set_verbosity(optuna.logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-processed datasets\n",
    "\n",
    "The pre-processing step reduced the dimensionality from 166 features to only 46."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The complete dataset already pre-processed \n",
    "df_complete = pd.read_hdf(\"./datasets/processed/df_complete.h5\", key=\"df_complete\")\n",
    "print(f\"Loaded from HDF5: {df_complete.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "# The filtered labeled dataset already pre-processed\n",
    "df_labeled = pd.read_hdf(\"./datasets/processed/df_labeled.h5\", key=\"df_labeled\")\n",
    "print(f\"Loaded from HDF5: {df_labeled.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "# The filtered unlabeled dataset already pre-processed\n",
    "df_unlabeled = pd.read_hdf(\"./datasets/processed/df_unlabeled.h5\", key=\"df_unlabeled\")\n",
    "print(f\"Loaded from HDF5: {df_unlabeled.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "# The edges dataset that maps relationships between transaction nodes\n",
    "df_edges = pd.read_hdf(\"./datasets/processed/df_edges.h5\", key=\"df_edges\")\n",
    "print(f\"Loaded from HDF5: {df_edges.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "\n",
    "# Summary of all datasets\n",
    "print(f\"\\nüìä Dataset Summary:\")\n",
    "print(f\"  - Features: {df_complete.shape[0]:,} transactions √ó {df_complete.shape[1] -2} features\")\n",
    "print(f\"  - Labeled: {df_labeled.shape[0]:,} transactions\")\n",
    "print(f\"  - Unlabeled: {df_unlabeled.shape[0]:,} transactions\")\n",
    "print(f\"  - Edges: {df_edges.shape[0]:,} transaction relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Strategy\n",
    "\n",
    "Let's apply the machine learning technics:\n",
    "\n",
    "1. Define overall parameters and make data splits\n",
    "2. Defining all training models to be used\n",
    "3. Defining all pipelines to be used during training\n",
    "4. Defining model parameters distribution for a optimization search \n",
    "5. Defining the object function and metrics to optimize\n",
    "6. Execute the optimized training\n",
    "7. Save all resulting models\n",
    "8. Validate all models and select the best models\n",
    "9. Use best models to predict unknown data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Define overall parameters and make data splits**\n",
    "\n",
    "Let`s prepare the dataset for training and validation\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining overall parameters\n",
    "random_seed = 4354 # PARAMETER: random seed\n",
    "test_size_split = 0.20 # PARAMETER: test set size\n",
    "n_stratified_splits = 2 # PARAMETER: number of folds\n",
    "n_pca_components = 0.95 # PARAMETER: PCA components to keep\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Prepare data (df_labeled already loaded: 46,564 √ó 48)\n",
    "x_labeled = df_labeled.drop(['class', 'txId'], axis=1)  # 46 features\n",
    "y_labeled = df_labeled['class']  # Binary target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_labeled, y_labeled,\n",
    "    test_size=test_size_split, \n",
    "    shuffle=True, \n",
    "    random_state=random_seed, \n",
    "    stratify=y_labeled) # stratified holdout\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=n_stratified_splits, \n",
    "                     shuffle=True, \n",
    "                     random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Defining all training models to be used**\n",
    "\n",
    "Let's define which models to use\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the individual models\n",
    "reg = ('LR', LogisticRegression())\n",
    "knn = ('KNN', KNeighborsClassifier())\n",
    "cart = ('CART', DecisionTreeClassifier())\n",
    "naive = ('NB', GaussianNB())\n",
    "svm = ('SVM', SVC())\n",
    "\n",
    "models = []\n",
    "models.append(reg)\n",
    "models.append(knn)\n",
    "models.append(cart)\n",
    "models.append(naive)\n",
    "models.append(svm)\n",
    "\n",
    "# Defining ensemble models\n",
    "bagging = ('Bag', BaggingClassifier())\n",
    "forest = ('RF', RandomForestClassifier())\n",
    "extra = ('ET', ExtraTreesClassifier())\n",
    "ada = ('Ada', AdaBoostClassifier())\n",
    "gradient = ('GB', GradientBoostingClassifier())\n",
    "voting = ('Voting', VotingClassifier(models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Defining all pipelines to be used during training**\n",
    "\n",
    "Let's define which ML pipelines to use during training.\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]\n",
    "\n",
    "This section focuses on selecting the most relevant features for distinguishing between licit (class 1) and illicit (class 2) transactions. We are aiming to reduce the feature dimensionality at the same time as maximizing the dissimilarity of the original dataset, thus extracting the most discriminative features and improving the model training performance. Let`s apply the following technics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pipelines\n",
    "pipelines = []\n",
    "std  = ('std', StandardScaler())  # Standardization\n",
    "pca = ('pca', PCA(n_components=n_pca_components))  # Feature reduction\n",
    "\n",
    "# Defining the pipelines, for future experimentation \n",
    "pipelines.append(('LR', Pipeline([std, pca, reg]))) \n",
    "pipelines.append(('KNN', Pipeline([std, pca, knn])))\n",
    "pipelines.append(('CART', Pipeline([std, pca, cart])))\n",
    "pipelines.append(('NB', Pipeline([std, pca, naive])))\n",
    "pipelines.append(('SVM', Pipeline([std, pca, svm])))\n",
    "pipelines.append(('Bag', Pipeline([std, pca, bagging])))\n",
    "pipelines.append(('RF', Pipeline([std, pca, forest])))\n",
    "pipelines.append(('ET', Pipeline([std, pca, extra])))\n",
    "pipelines.append(('Ada', Pipeline([std, pca, ada])))\n",
    "pipelines.append(('GB', Pipeline([std, pca, gradient])))\n",
    "#pipelines.append(('Vot', Pipeline([std, pca, voting])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Defining model parameters distribution for a grid search approach**\n",
    "\n",
    "Let's prepare the parameter distributions for a random grid search\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed parameter suggestions with unique names\n",
    "def suggest_params(trial, name):\n",
    "    if name == 'LR':\n",
    "        return {\n",
    "            'LR__C': trial.suggest_float('LR_C', 1e-4, 1e2, log=True),\n",
    "            'LR__solver': trial.suggest_categorical('LR_solver', ['lbfgs', 'newton-cg', 'sag', 'saga']),\n",
    "            'LR__penalty': trial.suggest_categorical('LR_penalty', ['l2']),\n",
    "            'LR__max_iter': trial.suggest_categorical('LR_max_iter', [1000, 2000, 5000]),\n",
    "            'LR__tol': trial.suggest_float('LR_tol', 1e-6, 1e-3, log=True)\n",
    "        }\n",
    "    elif name == 'KNN':\n",
    "        return {\n",
    "            'KNN__n_neighbors': trial.suggest_int('KNN_n_neighbors', 3, 21, step=2),\n",
    "            'KNN__weights': trial.suggest_categorical('KNN_weights', ['uniform', 'distance']),\n",
    "            'KNN__metric': trial.suggest_categorical('KNN_metric', ['euclidean', 'manhattan', 'minkowski']),\n",
    "            'KNN__p': trial.suggest_int('KNN_p', 1, 3)\n",
    "        }\n",
    "    elif name == 'CART':\n",
    "        return {\n",
    "            'CART__max_depth': trial.suggest_int('CART_max_depth', 3, 20),\n",
    "            'CART__min_samples_split': trial.suggest_int('CART_min_samples_split', 10, 50),\n",
    "            'CART__min_samples_leaf': trial.suggest_int('CART_min_samples_leaf', 5, 20),\n",
    "            'CART__criterion': trial.suggest_categorical('CART_criterion', ['gini', 'entropy'])\n",
    "        }\n",
    "    elif name == 'NB':\n",
    "        return {\n",
    "            'NB__var_smoothing': trial.suggest_float('NB_var_smoothing', 1e-12, 1e-6, log=True)\n",
    "        }\n",
    "    elif name == 'SVM':\n",
    "        return {\n",
    "            'SVM__C': trial.suggest_float('SVM_C', 1e-2, 1e3, log=True),\n",
    "            'SVM__kernel': trial.suggest_categorical('SVM_kernel', ['rbf', 'poly', 'sigmoid']),\n",
    "            'SVM__gamma': trial.suggest_categorical('SVM_gamma', ['scale', 'auto']),\n",
    "            'SVM__probability': True\n",
    "        }\n",
    "    elif name == 'RF':\n",
    "        return {\n",
    "            'RF__n_estimators': trial.suggest_int('RF_n_estimators', 100, 500, step=50),\n",
    "            'RF__max_depth': trial.suggest_int('RF_max_depth', 10, 25),\n",
    "            'RF__min_samples_split': trial.suggest_int('RF_min_samples_split', 5, 20),\n",
    "            'RF__min_samples_leaf': trial.suggest_int('RF_min_samples_leaf', 2, 10),\n",
    "            'RF__max_features': trial.suggest_categorical('RF_max_features', ['sqrt', 'log2', None]),\n",
    "            'RF__bootstrap': trial.suggest_categorical('RF_bootstrap', [True, False])\n",
    "        }\n",
    "    elif name == 'ET':\n",
    "        return {\n",
    "            'ET__n_estimators': trial.suggest_int('ET_n_estimators', 100, 500, step=50),\n",
    "            'ET__max_depth': trial.suggest_int('ET_max_depth', 10, 25),\n",
    "            'ET__min_samples_split': trial.suggest_int('ET_min_samples_split', 5, 20),\n",
    "            'ET__min_samples_leaf': trial.suggest_int('ET_min_samples_leaf', 2, 10),\n",
    "            'ET__max_features': trial.suggest_categorical('ET_max_features', ['sqrt', 'log2', None]),\n",
    "            'ET__bootstrap': trial.suggest_categorical('ET_bootstrap', [True, False])\n",
    "        }\n",
    "    elif name == 'GB':\n",
    "        return {\n",
    "            'GB__n_estimators': trial.suggest_int('GB_n_estimators', 100, 300, step=25),\n",
    "            'GB__learning_rate': trial.suggest_float('GB_learning_rate', 1e-2, 3e-1, log=True),\n",
    "            'GB__max_depth': trial.suggest_int('GB_max_depth', 3, 8),\n",
    "            'GB__subsample': trial.suggest_float('GB_subsample', 0.7, 0.9)\n",
    "        }\n",
    "    elif name == 'Ada':\n",
    "        return {\n",
    "            'Ada__n_estimators': trial.suggest_int('Ada_n_estimators', 50, 200, step=25),\n",
    "            'Ada__learning_rate': trial.suggest_float('Ada_learning_rate', 0.5, 1.5),\n",
    "            'Ada__algorithm': trial.suggest_categorical('Ada_algorithm', ['SAMME', 'SAMME.R'])\n",
    "        }\n",
    "    elif name == 'Bag':\n",
    "        return {\n",
    "            'Bag__n_estimators': trial.suggest_int('Bag_n_estimators', 50, 200, step=25),\n",
    "            'Bag__max_samples': trial.suggest_float('Bag_max_samples', 0.6, 0.9),\n",
    "            'Bag__max_features': trial.suggest_float('Bag_max_features', 0.7, 1.0)\n",
    "        }\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Defining the object function and metrics to optimize**\n",
    "\n",
    "Let`s define which metrics to optimize in the training search\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Multi-metric objective function for AML/KYT systems\n",
    "def aml_objective(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    #precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    #recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    #f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    #return 0.35*recall + 0.25*precision + 0.25*f1\n",
    "    return accuracy\n",
    "\n",
    "aml_scorer = make_scorer(aml_objective, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Execute the optimized training**\n",
    "\n",
    "Let's execute the training phase using the random grid search with cross validation and rank the best models by accuracy.\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna Bayesian Optimization - Fixed\n",
    "op_n_trials = 2\n",
    "op_n_jobs = 1\n",
    "optimized_models = []\n",
    "results = []\n",
    "\n",
    "print(\"üöÄ Optuna Optimization\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for name, pipe in pipelines:\n",
    "    print(f\"{name}:\", end=\" \")\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = suggest_params(trial, name)\n",
    "        if params: \n",
    "            pipe.set_params(**params)\n",
    "        scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=op_n_jobs)\n",
    "        return scores.mean()\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=random_seed))\n",
    "    \n",
    "    try:\n",
    "        study.optimize(objective, n_trials=op_n_trials, show_progress_bar=True)\n",
    "        best_score = study.best_value if study.trials else 0.0\n",
    "        if study.best_params:\n",
    "            pipe.set_params(**study.best_params)\n",
    "    except:\n",
    "        best_score = 0.0\n",
    "    \n",
    "    print(f\"‚úÖ {best_score:.3f}\")\n",
    "    optimized_models.append((name, pipe))\n",
    "    results.append(best_score)\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars = ax.bar([name for name, _ in optimized_models], results, color='skyblue', alpha=0.7)\n",
    "ax.set_ylabel('AML Score')\n",
    "ax.set_title('Model Performance')\n",
    "for bar, score in zip(bars, results):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{score:.3f}', ha='center', va='bottom')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üéØ Best: {[name for name, _ in optimized_models][np.argmax(results)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Save all resulting models**\n",
    "\n",
    "Let's save all models\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Try to save models from training\n",
    "    folderDir = \"./models/mvp-kyt-sup-main-v2\"\n",
    "    os.makedirs(folderDir, exist_ok=True)\n",
    "    for name, pipe in optimized_models:\n",
    "        joblib.dump(pipe, f\"{folderDir}/{name}.pkl\", compress=True)\n",
    "    print(f\"üíæ Saved {len(optimized_models)} models: {[name for name, _ in optimized_models]}\")\n",
    "except NameError:\n",
    "    # Load models if optimized_models doesn't exist\n",
    "    optimized_models = []\n",
    "    if os.path.exists(folderDir):\n",
    "        for file in os.listdir(folderDir):\n",
    "            if file.endswith('.pkl'):\n",
    "                name = file.replace('.pkl', '')\n",
    "                pipe = joblib.load(f\"{folderDir}/{file}\")\n",
    "                optimized_models.append((name, pipe))\n",
    "        print(f\"üìÅ Loaded {len(optimized_models)} models: {[name for name, _ in optimized_models]}\")\n",
    "    else:\n",
    "        print(\"‚ùå No models found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Validate all models and select the best models**\n",
    "\n",
    "Let's validate and select the best models\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best 3 models based on test accuracy\n",
    "test_results = []\n",
    "for name, pipe in optimized_models:\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_results.append((name, pipe, accuracy))\n",
    "    print(f\"{name}: Test Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Bar chart instead of boxplot for single values\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "names = [x[0] for x in test_results]\n",
    "accuracies = [x[2] for x in test_results]\n",
    "bars = ax.bar(names, accuracies, color='lightcoral', alpha=0.7)\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_title('Models Test Accuracy Comparison')\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "            f'{acc:.4f}', ha='center', va='bottom')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sort by test accuracy and get top 3\n",
    "test_results.sort(key=lambda x: x[2], reverse=True)\n",
    "best_optimized_models = [(name, model) for name, model, acc in test_results[:3]]\n",
    "\n",
    "print(f\"\\nüèÜ Final top 3 models: {[name for name, _ in best_optimized_models]}\")\n",
    "print(f\"üìä Test accuracies: {[f'{acc:.4f}' for _, _, acc in test_results[:3]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Use best models to predict unknown data**\n",
    "\n",
    "Let`s apply the model into unknown data\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best model to unlabeled data\n",
    "best_model = best_optimized_models[0][1]  # Champion model\n",
    "X_unlabeled = df_unlabeled.drop(['class', 'txId'], axis=1)\n",
    "\n",
    "predictions = best_model.predict(X_unlabeled)\n",
    "try:\n",
    "    probabilities = best_model.predict_proba(X_unlabeled)[:, 1]\n",
    "except:\n",
    "    probabilities = predictions.astype(float)\n",
    "\n",
    "print(f\"üîÆ Predictions on {len(X_unlabeled)} unlabeled transactions\")\n",
    "print(f\"Illicit predictions: {sum(predictions)} ({sum(predictions)/len(predictions)*100:.1f}%)\")\n",
    "print(f\"Risk scores range: {probabilities.min():.3f} - {probabilities.max():.3f}\")\n",
    "\n",
    "# Show first 10 predictions\n",
    "print(f\"\\nFirst 10 predictions: {predictions[:10]}\")\n",
    "print(f\"First 10 risk scores: {probabilities[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "[conclusion]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
