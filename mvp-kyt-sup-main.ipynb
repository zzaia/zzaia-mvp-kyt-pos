{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVP Know Your Transaction (KYT) - Transaction Risk Classification Engine\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This notebook presents a comprehensive implementation of a Transaction Risk Classification Engine for Anti-Money Laundering (AML) compliance in cryptocurrency transactions. The project addresses the critical need for risk assessment of Bitcoin transactions by combining traditional AML indicators with blockchain-specific risk factors.\n",
    "\n",
    "### Domain Context: Financial AML for Transactions\n",
    "\n",
    "#### Core Domain Definition\n",
    "Anti-Money Laundering (AML) for transactions encompasses the comprehensive framework of laws, regulations, procedures, and technological solutions designed to prevent criminals from disguising illegally obtained funds as legitimate income through the global financial system. This domain includes detection, prevention, and reporting of money laundering, terrorist financing, tax evasion, market manipulation, and misuse of public funds.\n",
    "\n",
    "### Problem Definition: Transaction Risk Classification Engine\n",
    "\n",
    "#### Problem Statement\n",
    "Develop a system that assigns risk classifications to cryptocurrency transactions in real-time, integrating traditional AML indicators with blockchain-specific risk factors including wallet clustering, transaction graph analysis, and counterparty reputation scoring.\n",
    "\n",
    "#### Technical Requirements\n",
    "- **Problem Type**: Classification \n",
    "- **Processing Speed**: Sub-second analysis for high-frequency transactions\n",
    "- **Difficulty Level**: High - requires complex multi-dimensional data processing\n",
    "- **Output Format**: Risk binary classification (illicit = 1 /licit = 2)\n",
    "\n",
    "#### Data Landscape\n",
    "The system can processes multiple data dimensions:\n",
    "- Transaction metadata (amounts, timestamps, fees)\n",
    "- Wallet addresses and clustering information\n",
    "- Transaction graph relationships and network topology\n",
    "- Counterparty databases and reputation scores\n",
    "- Sanctions lists and regulatory databases\n",
    "- Temporal patterns and behavioral baselines\n",
    "\n",
    "### References\n",
    "\n",
    "This notebook implementation is based on the comprehensive research and analysis conducted during the project development phase. The following reference documents were used in the composition of this initial description:\n",
    "\n",
    "- **Domain Research**: [current-domain.md](domains/current-domain.md) - Contains detailed market analysis, regulatory framework research, and commercial viability assessment for the Financial AML domain;\n",
    "- **Problem Analysis**: [current-problem.md](problems/current-problem.md) - Provides comprehensive problem refinement, technical requirements analysis, and solution approach evaluation;\n",
    "- **Dataset Evaluation**: [current-dataset.md](datasets/current-dataset.md) - Documents dataset selection criteria, suitability scoring, and detailed feature analysis for the Elliptic dataset;\n",
    "- **Dataset Analysis & Preprocessing**: [dataset-analysis-and-preprocessing.ipynb](datasets/scripts/dataset-analysis-and-preprocessing.ipynb) - Comprehensive Jupyter notebook containing Elliptic dataset download, exploratory data analysis, and ML preparation steps;\n",
    "\n",
    "These reference documents contain the foundational research that informed the technical approach, feature engineering strategy, and implementation decisions reflected in this notebook.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook serves as the primary entry point for the MVP KYT implementation and it can run independently, providing both technical implementation and business context for real cryptocurrency transaction risk assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "Comprehensive installation and import of all required libraries for machine learning procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-storage-blob in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (12.26.0)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from azure-storage-blob) (1.35.1)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from azure-storage-blob) (46.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from azure-storage-blob) (4.15.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from azure-storage-blob) (0.7.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from azure-core>=1.30.0->azure-storage-blob) (2.32.5)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from azure-core>=1.30.0->azure-storage-blob) (1.17.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from cryptography>=2.1.4->azure-storage-blob) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=2.1.4->azure-storage-blob) (2.23)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/raphaelpizzaia/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-storage-blob\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Utility functions for dataset processing and Azure blob storage operations.\n",
    "\"\"\"\n",
    "class AzureBlobDownloader:\n",
    "    \"\"\"\n",
    "    Azure Blob Storage downloader class for managing dataset downloads.\n",
    "\n",
    "    This class encapsulates Azure blob operations and maintains connection state\n",
    "    for efficient dataset management operations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, account_url, container_name):\n",
    "        \"\"\"\n",
    "        Initialize Azure blob downloader.\n",
    "\n",
    "        Args:\n",
    "            account_url (str): Azure storage account URL\n",
    "            container_name (str): Name of the blob container\n",
    "\n",
    "        Raises:\n",
    "            Exception: If connection to Azure fails or Azure SDK not available\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.account_url = account_url\n",
    "            self.container_name = container_name\n",
    "            self.blob_service_client = BlobServiceClient(account_url=account_url)\n",
    "            self.container_client = self.blob_service_client.get_container_client(container_name)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to initialize Azure Blob connection: {e}\")\n",
    "\n",
    "\n",
    "    def download_documents(self, project_folder, document_folder, base_path=\"../\"):\n",
    "        \"\"\"\n",
    "        Download dataset from Azure Blob Storage.\n",
    "\n",
    "        Args:\n",
    "            dataset_name: Name of the dataset directory in blob storage\n",
    "            base_path: Local base path for downloads (default: \"../\")\n",
    "\n",
    "        Returns:\n",
    "            bool: True if download successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            original_dir = Path(base_path) / project_folder \n",
    "            specific_dir = original_dir / document_folder\n",
    "\n",
    "            original_dir.mkdir(exist_ok=True)\n",
    "            specific_dir.mkdir(exist_ok=True)\n",
    "\n",
    "            remote_path = f\"{project_folder}/{document_folder}/\"\n",
    "            downloaded_files = 0\n",
    "\n",
    "            for blob in self.container_client.list_blobs(name_starts_with=remote_path):\n",
    "                blob_client = self.container_client.get_blob_client(blob.name)\n",
    "                local_file_path = Path(base_path) / blob.name\n",
    "                local_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                blob_data = blob_client.download_blob()\n",
    "                with open(local_file_path, \"wb\") as download_file:\n",
    "                    download_file.write(blob_data.readall())\n",
    "                downloaded_files += 1\n",
    "\n",
    "            print(f\"Successfully downloaded {downloaded_files} files from Azure Blob Storage\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download from Azure Blob Storage: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "azureClient = AzureBlobDownloader(\"https://stmvppos.blob.core.windows.net\", \"mvpkytsup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-processed datasets\n",
    "\n",
    "Let's load the pre-processed and compressed data from remote and local sources. The dataset is a composition of cryptocurrency transactions in the Bitcoin blockchain. \n",
    "\n",
    "It has 166 features, of which 92 features represent local transaction information and another 72 features represent aggregated information from one-hop neighboring transactions (directly linked transactions). Thus, the dataset already has curated information about the relationships between transactions. \n",
    "\n",
    "This is very important because money laundering and fraud patterns often involve coordinated transaction clusters and neighborhood patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from HDF5: (203769, 168) - All subsequent operations will use compressed data\n",
      "Loaded from HDF5: (46564, 168) - All subsequent operations will use compressed data\n",
      "Loaded from HDF5: (157205, 168) - All subsequent operations will use compressed data\n",
      "Loaded from HDF5: (234355, 2) - All subsequent operations will use compressed data\n",
      "\n",
      "ðŸ“Š Dataset Summary:\n",
      "  - Features: 203,769 transactions Ã— 166 features\n",
      "  - Labeled: 46,564 transactions\n",
      "  - Unlabeled: 157,205 transactions\n",
      "  - Edges: 234,355 transaction relationships\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "dataset_dir = Path(\"elliptic_bitcoin_dataset\")\n",
    "root_dir = Path(\"./datasets\")\n",
    "processed_dir = root_dir / \"processed\" / dataset_dir\n",
    "root_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Download processed data from Azure if not present locally\n",
    "if not processed_dir.exists() or not any(processed_dir.iterdir()):\n",
    "    print(f\"Local processed directory is empty. Downloading from Azure...\")\n",
    "    azureClient.download_documents(\"datasets/processed\", dataset_dir.name, base_path=\"./\")\n",
    "\n",
    "# The complete dataset already pre-processed \n",
    "df_complete = pd.read_hdf(processed_dir / \"df_complete.h5\", key=\"df_complete\")\n",
    "print(f\"Loaded from HDF5: {df_complete.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "# The filtered labeled dataset already pre-processed\n",
    "df_labeled = pd.read_hdf(processed_dir / \"df_labeled.h5\", key=\"df_labeled\")\n",
    "print(f\"Loaded from HDF5: {df_labeled.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "# The filtered unlabeled dataset already pre-processed\n",
    "df_unlabeled = pd.read_hdf(processed_dir / \"df_unlabeled.h5\", key=\"df_unlabeled\")\n",
    "print(f\"Loaded from HDF5: {df_unlabeled.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "# The edges dataset that maps relationships between transaction nodes\n",
    "df_edges = pd.read_hdf(processed_dir / \"df_edges.h5\", key=\"df_edges\")\n",
    "print(f\"Loaded from HDF5: {df_edges.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "# Summary of all datasets\n",
    "print(f\"\\nðŸ“Š Dataset Summary:\")\n",
    "print(f\"  - Features: {df_complete.shape[0]:,} transactions Ã— {df_complete.shape[1] -2} features\")\n",
    "print(f\"  - Labeled: {df_labeled.shape[0]:,} transactions\")\n",
    "print(f\"  - Unlabeled: {df_unlabeled.shape[0]:,} transactions\")\n",
    "print(f\"  - Edges: {df_edges.shape[0]:,} transaction relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Strategy\n",
    "\n",
    "Let's apply machine learning techniques to the labeled dataset portion using supervised learning, and apply the prediction to the unknown unlabeled dataset portion in order to establish a performance baseline for future improvements.\n",
    "\n",
    "Following these steps:\n",
    "\n",
    "1. Define overall parameters and make data splits;\n",
    "2. Define all training models to be used;\n",
    "3. Define all pipelines to be used during training;\n",
    "4. Define model parameter distributions for a grid search approach;\n",
    "5. Define the score function to be used during training;\n",
    "6. Execute the training;\n",
    "7. Save all resulting models;\n",
    "8. Validate all models and select the best models;\n",
    "9. Use best models to predict unknown data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Define overall parameters and make data splits**\n",
    "\n",
    "After splitting the labeled dataset into training and validation (test) sets, let's prepare the training dataset for training and validation using the stratified approach, which generates a fixed number of splits (folds) for the dataset following a fixed proportion of train/test samples. \n",
    "\n",
    "The main idea of this approach is to guarantee training without bias toward a specific dataset split because it maintains the same class proportion for each split (fold) generated. We use this technique in labeled and supervised learning, assuming that the dataset's pattern does not have significant changes over time.\n",
    "\n",
    "In this specific dataset, we consider the timestamp as a grouping factor for transactions but not as a changing factor for the dataset's pattern over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining overall parameters\n",
    "random_seed = 4354 # PARAMETER: random seed\n",
    "test_size_split = 0.20 # PARAMETER: test set size\n",
    "n_stratified_splits = 2 # PARAMETER: number of folds\n",
    "n_pca_components = 0.95 # PARAMETER: PCA components to keep\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Prepare data \n",
    "x_labeled = df_labeled.drop(['class', 'txId'], axis=1)\n",
    "y_labeled = df_labeled['class']  # Binary target\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_labeled, y_labeled,\n",
    "    test_size=test_size_split, \n",
    "    shuffle=True, \n",
    "    random_state=random_seed, \n",
    "    stratify=y_labeled) # stratified holdout\n",
    "\n",
    "# Cross-validation setup to be applied in the training set \n",
    "cv = StratifiedKFold(n_splits=n_stratified_splits, \n",
    "                     shuffle=True, \n",
    "                     random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Define all training models to be used**\n",
    "\n",
    "Let's define which models to use during training, selecting diverse ML algorithms covering linear, tree-based, probabilistic, and ensemble methods. \n",
    "\n",
    "Different algorithms capture different transaction patterns; ensemble methods reduce overfitting risk and can improve individual model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the individual models\n",
    "reg = ('LR', LogisticRegression())\n",
    "knn = ('KNN', KNeighborsClassifier())\n",
    "cart = ('CART', DecisionTreeClassifier())\n",
    "nav = ('NB', GaussianNB())\n",
    "svm = ('SVM', SVC())\n",
    "\n",
    "# Defining ensemble models\n",
    "bagging = ('Bag', BaggingClassifier())\n",
    "forest = ('RF', RandomForestClassifier())\n",
    "extra = ('ET', ExtraTreesClassifier())\n",
    "ada = ('Ada', AdaBoostClassifier())\n",
    "gradient = ('GB', GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Define all pipelines to be used during training**\n",
    "\n",
    "Let's define which ML pipelines to use during training, by configuring which pre-processing operations and models will be used in the training process. Pipelines also help avoid data leakage by ensuring that feature transformation is applied only to the training dataset portion.          \n",
    "\n",
    "For feature transformation, the standard scaler was used to ensure the best scale for feature values. By normalizing all values to a common metric, it reduces bias toward feature magnitude and enables subsequent operations to capture important patterns between features without being influenced mainly by their magnitude. All features contribute equally to pattern detection. This is especially important in finance because the difference between feature scales can be significant.\n",
    "\n",
    "For feature dimensionality reduction, Principal Component Analysis (PCA) was used to reduce from 166 to only 59 features. We aim to reduce feature dimensionality while maximizing the dissimilarity of the original dataset, thus extracting the most discriminative features and improving model training performance. It must be applied after the standard scaler to avoid the mentioned magnitude bias, and should be used in datasets that have a large quantity of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pipelines\n",
    "pipelines = []\n",
    "std  = ('std', StandardScaler())  # Standardization\n",
    "pca = ('pca', PCA(n_components=n_pca_components))  # Feature reduction\n",
    "\n",
    "# Defining the pipelines, for future experimentation \n",
    "pipelines.append(('LR', Pipeline([std, pca, reg])))  \n",
    "pipelines.append(('NB', Pipeline([std, pca, nav])))  \n",
    "pipelines.append(('KNN', Pipeline([std, pca, knn])))\n",
    "pipelines.append(('CART', Pipeline([std, pca, cart])))\n",
    "pipelines.append(('SVM', Pipeline([std, pca, svm])))\n",
    "pipelines.append(('Bag', Pipeline([std, pca, bagging])))\n",
    "pipelines.append(('RF', Pipeline([std, pca, forest])))\n",
    "pipelines.append(('ET', Pipeline([std, pca, extra])))\n",
    "pipelines.append(('Ada', Pipeline([std, pca, ada])))\n",
    "pipelines.append(('GB', Pipeline([std, pca, gradient])))\n",
    "\n",
    "# ENSEMBLE: SVM + KNN Voting Soft\n",
    "voting_soft = ('Vote-Soft', Pipeline([\n",
    "    std, \n",
    "    pca, \n",
    "    ('voting', VotingClassifier(\n",
    "        estimators=[\n",
    "            ('svm', SVC(probability=True)),  # Enable probability for soft voting\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ],\n",
    "        voting='soft',\n",
    "        weights=[0.6, 0.4]  # Weight SVM higher (better performer)\n",
    "    ))\n",
    "]))\n",
    "\n",
    "# ENSEMBLE: SVM + KNN Voting Hard\n",
    "voting_hard = ('Vote-Hard', Pipeline([\n",
    "    std,\n",
    "    pca,\n",
    "    ('voting', VotingClassifier(\n",
    "        estimators=[\n",
    "            ('svm', SVC()),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ],\n",
    "        voting='hard'\n",
    "    ))\n",
    "]))\n",
    "\n",
    "# ENSEMBLE: SVM + KNN Stacking\n",
    "stacking = ('Stack', Pipeline([\n",
    "    std,\n",
    "    pca,\n",
    "    ('stacking', StackingClassifier(\n",
    "        estimators=[\n",
    "            ('svm', SVC(probability=True)),\n",
    "            ('knn', KNeighborsClassifier())\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(),  # Meta-learner\n",
    "        cv=5,\n",
    "        passthrough=False  # Only use base predictions, not original features\n",
    "    ))\n",
    "]))\n",
    "\n",
    "pipelines.append(voting_soft)\n",
    "pipelines.append(voting_hard)\n",
    "pipelines.append(stacking)\n",
    "\n",
    "# ENSEMBLE: Bagging with SVM base estimator\n",
    "bag_svm = ('Bag-SVM', Pipeline([\n",
    "    std,\n",
    "    pca,\n",
    "    ('bagging', BaggingClassifier(\n",
    "        estimator=SVC(probability=True),\n",
    "        n_estimators=10,\n",
    "        max_samples=0.8,\n",
    "        max_features=0.8,\n",
    "        bootstrap=True,\n",
    "        random_state=random_seed\n",
    "    ))\n",
    "]))\n",
    "\n",
    "# ENSEMBLE: Bagging with KNN base estimator\n",
    "bag_knn = ('Bag-KNN', Pipeline([\n",
    "    std,\n",
    "    pca,\n",
    "    ('bagging', BaggingClassifier(\n",
    "        estimator=KNeighborsClassifier(),\n",
    "        n_estimators=10,\n",
    "        max_samples=0.8,\n",
    "        max_features=0.8,\n",
    "        bootstrap=True,\n",
    "        random_state=random_seed\n",
    "    ))\n",
    "]))\n",
    "\n",
    "# ENSEMBLE: AdaBoost with SVM base estimator\n",
    "ada_svm = ('Ada-SVM', Pipeline([\n",
    "    std,\n",
    "    pca,\n",
    "    ('adaboost', AdaBoostClassifier(\n",
    "        estimator=SVC(probability=True, kernel='linear'),  # Linear kernel required for AdaBoost\n",
    "        n_estimators=50,\n",
    "        learning_rate=1.0,\n",
    "        random_state=random_seed\n",
    "    ))\n",
    "]))\n",
    "\n",
    "# ENSEMBLE: AdaBoost with KNN base estimator\n",
    "ada_knn = ('Ada-KNN', Pipeline([\n",
    "    std,\n",
    "    pca,\n",
    "    ('adaboost', AdaBoostClassifier(\n",
    "        estimator=KNeighborsClassifier(),\n",
    "        n_estimators=50,\n",
    "        learning_rate=1.0,\n",
    "        algorithm='SAMME',  # SAMME works better with KNN\n",
    "        random_state=random_seed\n",
    "    ))\n",
    "]))\n",
    "\n",
    "pipelines.append(bag_svm)\n",
    "pipelines.append(bag_knn)\n",
    "pipelines.append(ada_svm)\n",
    "pipelines.append(ada_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Define model parameter distributions for a grid search approach**\n",
    "\n",
    "Let's prepare the parameter distributions for a random grid search, by using a distribution of possible parameter values, so that the training phase can explore the best performance models also from the perspective of their hyperparameters. This is a better solution than the common grid search approach because it can explore a broader hyperparameter space and is often faster. \n",
    "\n",
    "Three types of parameter distributions were used:\n",
    "\n",
    "- uniform: Continuous values with equal probability across a range, used when all values in the range are equally valid;\n",
    "- loguniform: Continuous values on logarithmic scale (exponential distribution), used when smaller values are often better;\n",
    "- randint: Discrete integer values with equal probability, used for discrete hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter distributions for RandomizedSearchCV\n",
    "# Enhanced with log-uniform distributions and comprehensive documentation\n",
    "# Optimized for financial/cryptocurrency transaction risk classification\n",
    "\n",
    "param_distributions = {\n",
    "    'LR': {\n",
    "        # REGULARIZATION STRENGTH (C): Inverse regularization strength\n",
    "        # Lower values = stronger regularization = simpler model (prevent overfitting)\n",
    "        # Higher values = weaker regularization = more complex model\n",
    "        # Log-uniform for exponential search across orders of magnitude\n",
    "        # Critical for financial data: balance between model complexity and generalization\n",
    "        'LR__C': loguniform(1e-4, 1e2),\n",
    "\n",
    "        # OPTIMIZATION SOLVER: Algorithm for weight optimization\n",
    "        # 'lbfgs': Fast for small datasets, good convergence, handles L2/none penalty\n",
    "        # 'newton-cg': Robust for large datasets, handles L2/none penalty\n",
    "        # 'sag': Stochastic Average Gradient, fast for large datasets\n",
    "        # 'saga': Supports all penalties, good for sparse features (financial data)\n",
    "        # Removed 'liblinear': slower for datasets > 10K samples\n",
    "        'LR__solver': ['lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "\n",
    "        # REGULARIZATION TYPE: Controls feature selection and overfitting\n",
    "        # 'l2': Ridge regression, keeps all features, reduces coefficients\n",
    "        # 'none': No regularization, may overfit with many features\n",
    "        # Removed 'l1': Lasso causes issues with solver compatibility\n",
    "        # Financial context: L2 better for correlated transaction features\n",
    "        'LR__penalty': ['l2', 'none'],\n",
    "\n",
    "        # MAXIMUM ITERATIONS: Convergence limit for optimization\n",
    "        # Higher values ensure convergence but increase training time\n",
    "        # Financial data often needs more iterations due to class imbalance\n",
    "        # 2000+ recommended for 46K+ samples to avoid convergence warnings\n",
    "        'LR__max_iter': [1000, 2000, 5000],\n",
    "\n",
    "        # CONVERGENCE TOLERANCE: Stopping criteria precision\n",
    "        # Lower values = more precise convergence = longer training time\n",
    "        # Financial models need precise convergence for regulatory compliance\n",
    "        # 1e-6: High precision, 1e-4: Fast convergence\n",
    "        'LR__tol': loguniform(1e-6, 1e-3)\n",
    "    },\n",
    "\n",
    "    'KNN': {\n",
    "        # NUMBER OF NEIGHBORS: Core hyperparameter for KNN algorithm\n",
    "        # Lower values = more complex decision boundary = higher variance\n",
    "        # Higher values = smoother decision boundary = higher bias\n",
    "        # Financial context: 5-15 often optimal for transaction classification\n",
    "        # Odd numbers prevent ties in binary classification\n",
    "        'KNN__n_neighbors': randint(3, 21),\n",
    "\n",
    "        # WEIGHT FUNCTION: How neighbors influence prediction\n",
    "        # 'uniform': All neighbors weighted equally\n",
    "        # 'distance': Closer neighbors have higher influence\n",
    "        # Financial context: 'distance' often better for transaction patterns\n",
    "        'KNN__weights': ['uniform', 'distance'],\n",
    "\n",
    "        # DISTANCE METRIC: How to measure similarity between transactions\n",
    "        # 'euclidean': Standard L2 distance, good for continuous features\n",
    "        # 'manhattan': L1 distance, robust to outliers (good for financial data)\n",
    "        # 'minkowski': Generalization, controlled by 'p' parameter\n",
    "        'KNN__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "\n",
    "        # MINKOWSKI POWER: Only used when metric='minkowski'\n",
    "        # p=1: Manhattan distance, p=2: Euclidean distance\n",
    "        # Financial data: p=1 often better due to outlier robustness\n",
    "        'KNN__p': randint(1, 3)\n",
    "    },\n",
    "\n",
    "    'CART': {\n",
    "        # MAXIMUM TREE DEPTH: Primary overfitting control\n",
    "        # Lower values = simpler tree = less overfitting = higher bias\n",
    "        # Financial context: 5-15 often optimal for interpretability vs performance\n",
    "        # Too deep trees memorize transactions instead of learning patterns\n",
    "        'CART__max_depth': randint(3, 20),\n",
    "\n",
    "        # MINIMUM SAMPLES TO SPLIT: Prevents splitting on small sample sizes\n",
    "        # Higher values = more conservative splits = less overfitting\n",
    "        # Financial context: 10-50 good for 46K+ dataset to ensure robust splits\n",
    "        'CART__min_samples_split': randint(10, 50),\n",
    "\n",
    "        # MINIMUM SAMPLES PER LEAF: Ensures leaf nodes have sufficient samples\n",
    "        # Higher values = smoother predictions = less overfitting\n",
    "        # Critical for financial data: prevents decisions based on few transactions\n",
    "        'CART__min_samples_leaf': randint(5, 20),\n",
    "\n",
    "        # SPLIT QUALITY MEASURE: Criterion for evaluating split quality\n",
    "        # 'gini': Gini impurity, faster computation\n",
    "        # 'entropy': Information gain, potentially better separation\n",
    "        # Financial context: both work well, entropy slightly better for imbalanced data\n",
    "        'CART__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "\n",
    "    'NB': {\n",
    "        # VARIANCE SMOOTHING: Laplace smoothing for numerical stability\n",
    "        # Prevents zero probabilities when features have zero variance\n",
    "        # Log-uniform for exponential search across precision levels\n",
    "        # Financial context: 1e-9 to 1e-6 range good for PCA-transformed features\n",
    "        'NB__var_smoothing': loguniform(1e-12, 1e-6),\n",
    "\n",
    "        # CLASS PRIORS: Prior probabilities for each class\n",
    "        # None: Learn priors from training data (recommended)\n",
    "        # Custom priors could be set based on known illicit transaction rates\n",
    "        'NB__priors': [None]\n",
    "    },\n",
    "\n",
    "    'SVM': {\n",
    "        # REGULARIZATION PARAMETER: Trade-off between margin and misclassification\n",
    "        # Lower C = wider margin = more regularization = simpler model\n",
    "        # Higher C = narrower margin = less regularization = complex model\n",
    "        # Log-uniform critical for SVM: performance varies across orders of magnitude\n",
    "        # Financial context: Often needs tuning from 0.01 to 1000\n",
    "        'SVM__C': loguniform(1e-2, 1e3),\n",
    "\n",
    "        # KERNEL FUNCTION: Maps features to higher-dimensional space\n",
    "        # 'rbf': Radial basis function, good for non-linear financial patterns\n",
    "        # 'poly': Polynomial kernel, can capture feature interactions\n",
    "        # 'sigmoid': Tanh kernel, neural network-like behavior\n",
    "        # Removed 'linear': redundant with LogisticRegression for PCA features\n",
    "        'SVM__kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "\n",
    "        # KERNEL COEFFICIENT: Controls kernel shape and influence\n",
    "        # 'scale': 1/(n_features * X.var()) - good default for normalized data\n",
    "        # 'auto': 1/n_features - simpler scaling\n",
    "        # Log-uniform range would be loguniform(1e-6, 1e-1) for custom values\n",
    "        'SVM__gamma': ['scale', 'auto']\n",
    "    },\n",
    "\n",
    "    'RF': {\n",
    "        # NUMBER OF TREES: Primary performance vs speed trade-off\n",
    "        # More trees = better performance = longer training/prediction time\n",
    "        # Financial context: 100-500 often optimal, diminishing returns after 300\n",
    "        # Real-time KYT systems need to balance accuracy with inference speed\n",
    "        'RF__n_estimators': randint(100, 500),\n",
    "\n",
    "        # MAXIMUM TREE DEPTH: Individual tree complexity control\n",
    "        # None = trees grow until pure leaves (may overfit)\n",
    "        # Specific values prevent overfitting in ensemble\n",
    "        # Financial context: 10-25 good for transaction complexity\n",
    "        'RF__max_depth': randint(10, 25),\n",
    "\n",
    "        # MINIMUM SAMPLES TO SPLIT: Conservative splitting threshold\n",
    "        # Higher values = more robust trees = better generalization\n",
    "        # Financial data: 5-20 good for 46K+ samples\n",
    "        'RF__min_samples_split': randint(5, 20),\n",
    "\n",
    "        # MINIMUM SAMPLES PER LEAF: Leaf node size constraint\n",
    "        # Prevents overfitting to individual transactions\n",
    "        # Financial context: 2-10 ensures meaningful leaf nodes\n",
    "        'RF__min_samples_leaf': randint(2, 10),\n",
    "\n",
    "        # FEATURE SUBSET SIZE: Number of features per tree split\n",
    "        # 'sqrt': sqrt(n_features) â‰ˆ 7 features for 46 total\n",
    "        # 'log2': log2(n_features) â‰ˆ 6 features for 46 total\n",
    "        # None: Use all features (may reduce diversity)\n",
    "        # Financial context: 'sqrt' often optimal for transaction features\n",
    "        'RF__max_features': ['sqrt', 'log2', None],\n",
    "\n",
    "        # BOOTSTRAP SAMPLING: Sample replacement for tree training\n",
    "        # True: Standard random forest with replacement sampling\n",
    "        # False: Use entire dataset for each tree (less diversity)\n",
    "        # Financial context: True recommended for better generalization\n",
    "        'RF__bootstrap': [True, False]\n",
    "    },\n",
    "\n",
    "    'ET': {\n",
    "        # Extra Trees: Similar to Random Forest but with random splits\n",
    "        # Generally faster training, sometimes better performance\n",
    "        # Parameters similar to Random Forest but more aggressive randomization\n",
    "\n",
    "        'ET__n_estimators': randint(100, 500),          # Number of trees in ensemble\n",
    "        'ET__max_depth': randint(10, 25),               # Maximum depth of trees\n",
    "        'ET__min_samples_split': randint(5, 20),        # Min samples to split node\n",
    "        'ET__min_samples_leaf': randint(2, 10),         # Min samples at leaf\n",
    "        'ET__max_features': ['sqrt', 'log2', None],     # Random feature subset size\n",
    "        'ET__bootstrap': [True, False]                  # Bootstrap sampling toggle\n",
    "    },\n",
    "\n",
    "    'GB': {\n",
    "        # BOOSTING STAGES: Number of sequential weak learners\n",
    "        # More stages = better performance = higher overfitting risk\n",
    "        # Financial context: 100-300 often optimal, early stopping recommended\n",
    "        'GB__n_estimators': randint(100, 300),\n",
    "\n",
    "        # LEARNING RATE: Step size shrinkage for gradient updates\n",
    "        # Lower rates = more conservative learning = need more estimators\n",
    "        # Higher rates = aggressive learning = risk of overshooting optimum\n",
    "        # Log-uniform for exponential search: 0.01-0.3 typical range\n",
    "        # Financial context: 0.05-0.15 often optimal for stability\n",
    "        'GB__learning_rate': loguniform(1e-2, 3e-1),\n",
    "\n",
    "        # INDIVIDUAL TREE DEPTH: Weak learner complexity\n",
    "        # Gradient boosting uses shallow trees (stumps to 8 levels)\n",
    "        # Higher depth = stronger individual learners = risk of overfitting\n",
    "        # Financial context: 3-8 optimal for transaction patterns\n",
    "        'GB__max_depth': randint(3, 8),\n",
    "\n",
    "        # SUBSAMPLE FRACTION: Stochastic gradient boosting\n",
    "        # < 1.0 = use random subset of samples for each tree\n",
    "        # Reduces overfitting and improves generalization\n",
    "        # Financial context: 0.7-0.9 good for large transaction datasets\n",
    "        'GB__subsample': uniform(0.7, 0.2)  # 0.7 to 0.9 range\n",
    "    },\n",
    "\n",
    "    'Ada': {\n",
    "        # ADAPTIVE BOOSTING: Sequential weak learner weighting\n",
    "        # Focuses on previously misclassified transactions\n",
    "\n",
    "        # NUMBER OF WEAK LEARNERS: Maximum boosting rounds\n",
    "        # AdaBoost often needs fewer estimators than Gradient Boosting\n",
    "        # Financial context: 50-200 sufficient for most transaction patterns\n",
    "        'Ada__n_estimators': randint(50, 200),\n",
    "\n",
    "        # LEARNING RATE: Weight applied to each weak classifier\n",
    "        # Lower rates = more conservative = better generalization\n",
    "        # Higher rates = aggressive = faster convergence but overfitting risk\n",
    "        # Financial context: 0.5-1.5 range for transaction classification\n",
    "        'Ada__learning_rate': uniform(0.5, 1.0),  # 0.5 to 1.5 range\n",
    "\n",
    "        # BOOSTING ALGORITHM: AdaBoost variant\n",
    "        # 'SAMME': Discrete AdaBoost, works with any base classifier\n",
    "        # 'SAMME.R': Real AdaBoost, requires probability estimates\n",
    "        # Financial context: SAMME.R often faster and more accurate\n",
    "        'Ada__algorithm': ['SAMME', 'SAMME.R']\n",
    "    },\n",
    "\n",
    "    'Bag': {\n",
    "        # BOOTSTRAP AGGREGATING: Parallel ensemble method\n",
    "        # Reduces overfitting through averaging multiple models\n",
    "\n",
    "        'Bag__n_estimators': randint(50, 200),          # Number of base estimators\n",
    "\n",
    "        # SAMPLE FRACTION: Proportion of dataset for each estimator\n",
    "        # Lower values = more diversity = better generalization\n",
    "        # Higher values = more stable individual models\n",
    "        # Financial context: 0.6-0.9 good for transaction data diversity\n",
    "        'Bag__max_samples': uniform(0.6, 0.3),  # 0.6 to 0.9 range\n",
    "\n",
    "        # FEATURE FRACTION: Proportion of features for each estimator\n",
    "        # Creates feature diversity in ensemble\n",
    "        # Financial context: 0.7-1.0 to maintain transaction pattern integrity\n",
    "        'Bag__max_features': uniform(0.7, 0.3)   # 0.7 to 1.0 range\n",
    "    },\n",
    "    \n",
    "    'Vote-Soft': {\n",
    "        # SVM hyperparameters for voting ensemble\n",
    "        'voting__svm__C': loguniform(1e-2, 1e3),\n",
    "        'voting__svm__kernel': ['rbf', 'poly'],\n",
    "        'voting__svm__gamma': ['scale', 'auto'],\n",
    "        \n",
    "        # KNN hyperparameters for voting ensemble\n",
    "        'voting__knn__n_neighbors': randint(3, 21),\n",
    "        'voting__knn__weights': ['uniform', 'distance'],\n",
    "        'voting__knn__metric': ['euclidean', 'manhattan'],\n",
    "        \n",
    "        # Voting weights optimization\n",
    "        'voting__weights': [[0.7, 0.3], [0.6, 0.4], [0.5, 0.5], [0.8, 0.2]]\n",
    "    },\n",
    "    \n",
    "    'Vote-Hard': {\n",
    "        # SVM hyperparameters for voting ensemble\n",
    "        'voting__svm__C': loguniform(1e-2, 1e3),\n",
    "        'voting__svm__kernel': ['rbf', 'poly'],\n",
    "        'voting__svm__gamma': ['scale', 'auto'],\n",
    "        \n",
    "        # KNN hyperparameters for voting ensemble\n",
    "        'voting__knn__n_neighbors': randint(3, 21),\n",
    "        'voting__knn__weights': ['uniform', 'distance'],\n",
    "        'voting__knn__metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    \n",
    "    'Stack': {\n",
    "        # SVM hyperparameters for stacking\n",
    "        'stacking__svm__C': loguniform(1e-2, 1e3),\n",
    "        'stacking__svm__kernel': ['rbf', 'poly'],\n",
    "        'stacking__svm__gamma': ['scale', 'auto'],\n",
    "        \n",
    "        # KNN hyperparameters for stacking\n",
    "        'stacking__knn__n_neighbors': randint(3, 21),\n",
    "        'stacking__knn__weights': ['uniform', 'distance'],\n",
    "        'stacking__knn__metric': ['euclidean', 'manhattan'],\n",
    "        \n",
    "        # Meta-learner (LogisticRegression) hyperparameters\n",
    "        'stacking__final_estimator__C': loguniform(1e-4, 1e2),\n",
    "        'stacking__final_estimator__solver': ['lbfgs', 'saga'],\n",
    "        'stacking__final_estimator__max_iter': [1000, 2000]\n",
    "    },\n",
    "    \n",
    "    'Bag-SVM': {\n",
    "        # Base SVM estimator parameters\n",
    "        'bagging__estimator__C': loguniform(1e-2, 1e3),\n",
    "        'bagging__estimator__kernel': ['rbf', 'poly', 'linear'],\n",
    "        'bagging__estimator__gamma': ['scale', 'auto'],\n",
    "        \n",
    "        # Bagging ensemble parameters\n",
    "        'bagging__n_estimators': randint(10, 100),\n",
    "        'bagging__max_samples': uniform(0.5, 0.4),  # 0.5 to 0.9\n",
    "        'bagging__max_features': uniform(0.5, 0.4),  # 0.5 to 0.9\n",
    "        'bagging__bootstrap': [True, False]\n",
    "    },\n",
    "    \n",
    "    'Bag-KNN': {\n",
    "        # Base KNN estimator parameters\n",
    "        'bagging__estimator__n_neighbors': randint(3, 21),\n",
    "        'bagging__estimator__weights': ['uniform', 'distance'],\n",
    "        'bagging__estimator__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "        \n",
    "        # Bagging ensemble parameters\n",
    "        'bagging__n_estimators': randint(10, 100),\n",
    "        'bagging__max_samples': uniform(0.5, 0.4),  # 0.5 to 0.9\n",
    "        'bagging__max_features': uniform(0.5, 0.4),  # 0.5 to 0.9\n",
    "        'bagging__bootstrap': [True, False]\n",
    "    },\n",
    "    \n",
    "    'Ada-SVM': {\n",
    "        # Base SVM estimator parameters (linear kernel for AdaBoost compatibility)\n",
    "        'adaboost__estimator__C': loguniform(1e-2, 1e2),\n",
    "        \n",
    "        # AdaBoost ensemble parameters\n",
    "        'adaboost__n_estimators': randint(30, 150),\n",
    "        'adaboost__learning_rate': uniform(0.5, 1.5),  # 0.5 to 2.0\n",
    "        'adaboost__algorithm': ['SAMME', 'SAMME.R']\n",
    "    },\n",
    "    \n",
    "    'Ada-KNN': {\n",
    "        # Base KNN estimator parameters\n",
    "        'adaboost__estimator__n_neighbors': randint(3, 21),\n",
    "        'adaboost__estimator__weights': ['uniform', 'distance'],\n",
    "        'adaboost__estimator__metric': ['euclidean', 'manhattan'],\n",
    "        \n",
    "        # AdaBoost ensemble parameters\n",
    "        'adaboost__n_estimators': randint(30, 150),\n",
    "        'adaboost__learning_rate': uniform(0.5, 1.5),  # 0.5 to 2.0\n",
    "        'adaboost__algorithm': ['SAMME']  # SAMME works better with KNN\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Define the score function to be used during training**\n",
    "\n",
    "Let's define the score function that will be used to measure each model's performance. Instead of using just one metric alone, the function enables us to define a weighted multi-metric approach, defining which metrics would be more important for the model's performance. The chosen score is a combination of three important metrics: \n",
    "\n",
    "- Recall measures how good the model is at not having false negatives;\n",
    "- Precision measures how good the model is at not having false positives;  \n",
    "- Accuracy measures how good the model is at not having false classifications;\n",
    "\n",
    "In financial transaction risk assessments, it is more important to have fewer false negatives than false positive classifications, because it would be less risky to block a transaction wrongly considered illicit than to not block a transaction wrongly considered licit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aml_composite_score(y_true, y_pred):\n",
    "    \"\"\"Custom scoring balancing multiple AML metrics\"\"\"\n",
    "    #accuracy = accuracy_score(y_true, y_pred)\n",
    "    #recall = recall_score(y_true, y_pred, pos_label='1')  # Illicit detection\n",
    "    #precision = precision_score(y_true, y_pred, pos_label='1') # Illicit detection\n",
    "    f1 = f1_score(y_true, y_pred, pos_label='1')  # Illicit detection   \n",
    "\n",
    "    # Weighted combination emphasizing illicit detection\n",
    "    #return 0.6 * recall + 0.2 * precision + 0.2 * accuracy\n",
    "    return f1\n",
    "\n",
    "composite_scorer = make_scorer(aml_composite_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Execute the training** [CAN BE SKIPPED ~ 2h]\n",
    "\n",
    "Let's execute the training phase using random grid search and execute it in parallel, with cross-validation of all dataset splits (folds) and rank the best models by score function.\n",
    "\n",
    "The final plot will display all model training samples with their mean and variance performance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Training Models with RandomizedSearchCV Optimization...\n",
      "Training 17 models: Basic + Ensemble methods\n",
      "------------------------------------------------------------\n",
      "Training LR... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.1119 (Â±0.0109)\n",
      "Training NB... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.3520 (Â±0.0059)\n",
      "Training KNN... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8382 (Â±0.0048)\n",
      "Training CART... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.7836 (Â±0.0088)\n",
      "Training SVM... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8806 (Â±0.0062)\n",
      "Training Bag... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8379 (Â±0.0097)\n",
      "Training RF... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8342 (Â±0.0082)\n",
      "Training ET... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8226 (Â±0.0016)\n",
      "Training Ada... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.7663 (Â±0.0044)\n",
      "Training GB... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8539 (Â±0.0020)\n",
      "Training Vote-Soft... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8528 (Â±0.0073)\n",
      "Training Vote-Hard... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8257 (Â±0.0060)\n",
      "Training Stack... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8555 (Â±0.0046)\n",
      "Training Bag-SVM... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8759 (Â±0.0056)\n",
      "Training Bag-KNN... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "âœ… 0.8465 (Â±0.0028)\n",
      "Training Ada-SVM... Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "gs_iter = 5  # PARAMETER: Number of parameter combinations to try\n",
    "gs_jobs = -1  # PARAMETER: Use all available cores\n",
    "gs_verbosity = 1  # PARAMETER: Verbosity level\n",
    "\n",
    "# Create result collections\n",
    "training_models = []\n",
    "cv_results_all = []  # Store all CV scores for boxplot\n",
    "\n",
    "print(\"ðŸ” Training Models with RandomizedSearchCV Optimization...\")\n",
    "print(f\"Training {len(pipelines)} models: Basic + Ensemble methods\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, pipe in pipelines:\n",
    "    print(f\"Training {name}...\", end=\" \")\n",
    "    random_search = RandomizedSearchCV(\n",
    "            estimator=pipe,\n",
    "            param_distributions=param_distributions[name],\n",
    "            n_iter=gs_iter,\n",
    "            cv=cv,\n",
    "            verbose=gs_verbosity,\n",
    "            scoring=composite_scorer,\n",
    "            random_state=random_seed,\n",
    "            n_jobs=gs_jobs\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_score = random_search.best_score_\n",
    "    std_score = random_search.cv_results_['std_test_score'][random_search.best_index_]\n",
    "    \n",
    "    # Extract CV scores for best parameter combination from RandomizedSearchCV results\n",
    "    best_index = random_search.best_index_\n",
    "    cv_scores_key = f'split{cv.n_splits-1}_test_score'  # Get all split scores\n",
    "    cv_scores = []\n",
    "    for split in range(cv.n_splits):\n",
    "        split_key = f'split{split}_test_score'\n",
    "        cv_scores.append(random_search.cv_results_[split_key][best_index])\n",
    "    cv_results_all.append(cv_scores)\n",
    "        \n",
    "    print(f\"âœ… {best_score:.4f} (Â±{std_score:.4f})\")\n",
    "    \n",
    "    training_models.append((name, best_model))\n",
    "\n",
    "# Create boxplot with individual CV fold scores\n",
    "fig = plt.figure(figsize=(25,6))\n",
    "fig.suptitle('Trained Models Comparison - CV Score Distribution') \n",
    "ax = fig.add_subplot(111) \n",
    "plt.boxplot(cv_results_all, labels=[x[0] for x, _ in training_models])\n",
    "ax.set_ylabel('Cross-Validation Accuracy')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.show()\n",
    "\n",
    "optimized_models = training_models.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Save or load all resulting models**\n",
    "\n",
    "Let's save all resulting trained models locally or retrieve previously trained models from local or remote sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saved 10 models: ['LR', 'NB', 'KNN', 'CART', 'SVM', 'Bag', 'RF', 'ET', 'Ada', 'GB']\n"
     ]
    }
   ],
   "source": [
    "# Save or Load models\n",
    "dataset_str  = \"mvp-kyt-sup-main\"\n",
    "models_str  = \"models\"\n",
    "folder_str = f\"./{models_str}/{dataset_str}\"\n",
    "try:\n",
    "    os.makedirs(folder_str, exist_ok=True)\n",
    "    for name, pipe in optimized_models:\n",
    "        joblib.dump(pipe, f\"{folder_str}/{name}.pkl\", compress=True)\n",
    "    print(f\"ðŸ’¾ Saved {len(optimized_models)} models: {[name for name, _ in optimized_models]}\")\n",
    "except:\n",
    "    if azureClient.download_documents(models_str, dataset_str, base_path=\"./\"):\n",
    "        print(\"Download from Azure Blob Storage completed successfully.\")\n",
    "\n",
    "    folder_dir = Path(folder_str)\n",
    "    if(folder_dir.exists() and any(folder_dir.iterdir())):\n",
    "        print(\"âŒ No models were trained.\")\n",
    "        optimized_models = []\n",
    "        if os.path.exists(folder_dir):\n",
    "            for file in os.listdir(folder_dir):\n",
    "                if file.endswith('.pkl'):\n",
    "                    name = file.replace('.pkl', '')\n",
    "                    pipe = joblib.load(f\"{folder_str}/{file}\")\n",
    "                    optimized_models.append((name, pipe))\n",
    "            print(f\"ðŸ“ Loaded {len(optimized_models)} models: {[name for name, _ in optimized_models]}\")\n",
    "        else:\n",
    "            print(\"âŒ No models found\")\n",
    "    else:\n",
    "        print(\"âŒ No models available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Validate all models and select the best models**\n",
    "\n",
    "Let's validate and select the best models by applying all trained pipelines to the previously generated testing set using the multi-metric score function.    \n",
    "\n",
    "Model validation with an unseen dataset during training can give us an approximate measure of how the model would perform in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† Final top models:\n",
      "------------------------------\n",
      "SVM: Test performance = 0.8855\n",
      "KNN: Test performance = 0.8525\n",
      "GB: Test performance = 0.8490\n",
      "Bag: Test performance = 0.8413\n",
      "ET: Test performance = 0.8283\n",
      "RF: Test performance = 0.8268\n",
      "CART: Test performance = 0.7777\n",
      "Ada: Test performance = 0.7437\n",
      "NB: Test performance = 0.3462\n",
      "LR: Test performance = 0.1998\n"
     ]
    }
   ],
   "source": [
    "# Select best models based on test accuracy\n",
    "test_results = []\n",
    "for name, pipe in optimized_models:\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    accuracy = aml_composite_score(y_test, y_pred)\n",
    "    test_results.append((name, accuracy))\n",
    "\n",
    "# Sort by test accuracy and get top 3\n",
    "test_results.sort(key=lambda x: x[1], reverse=True)\n",
    "print(f\"\\nðŸ† Final top models:\")\n",
    "print('-'*30)\n",
    "for name, acc in test_results:\n",
    "    print(f\"{name}: Test performance = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Use best models to predict unknown data**\n",
    "\n",
    "Let's apply the best pipeline model to unknown dataâ€”data that does not have labelsâ€”and display the results to get an idea of how the landscape of unknown illicit transactions could be. This measure can also be used for comparison with future improvements to the machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Prediction Distribution:\n",
      "Model used: SVM\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Prediction Summary:\n",
      "  Total predictions: 157,205\n",
      "  Illicit transactions: 12,675\n",
      "  Licit transactions: 144,530\n",
      "  Imbalance ratio: 11.4:1\n",
      "\n",
      "ðŸ”® Sample illicit transactions (showing 100 of 12,675 total)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>230658142</td>\n",
       "      <td>Illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>230335026</td>\n",
       "      <td>Illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>230471924</td>\n",
       "      <td>Illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>232431890</td>\n",
       "      <td>Illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>230456382</td>\n",
       "      <td>Illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>231597173</td>\n",
       "      <td>Illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>230530227</td>\n",
       "      <td>Illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>230594125</td>\n",
       "      <td>Illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>231995279</td>\n",
       "      <td>Illicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>5119724</td>\n",
       "      <td>Illicit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           txId prediction\n",
       "54    230658142    Illicit\n",
       "118   230335026    Illicit\n",
       "159   230471924    Illicit\n",
       "234   232431890    Illicit\n",
       "285   230456382    Illicit\n",
       "...         ...        ...\n",
       "3596  231597173    Illicit\n",
       "3622  230530227    Illicit\n",
       "3695  230594125    Illicit\n",
       "3795  231995279    Illicit\n",
       "3893    5119724    Illicit\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”® Sample licit transactions (showing 100 of 144,530 total)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230425980</td>\n",
       "      <td>Licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5530458</td>\n",
       "      <td>Licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232022460</td>\n",
       "      <td>Licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230460314</td>\n",
       "      <td>Licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230459870</td>\n",
       "      <td>Licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>232368272</td>\n",
       "      <td>Licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>230521273</td>\n",
       "      <td>Licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>230658997</td>\n",
       "      <td>Licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>231179660</td>\n",
       "      <td>Licit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>230967090</td>\n",
       "      <td>Licit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          txId prediction\n",
       "0    230425980      Licit\n",
       "1      5530458      Licit\n",
       "2    232022460      Licit\n",
       "3    230460314      Licit\n",
       "4    230459870      Licit\n",
       "..         ...        ...\n",
       "96   232368272      Licit\n",
       "97   230521273      Licit\n",
       "98   230658997      Licit\n",
       "99   231179660      Licit\n",
       "100  230967090      Licit\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply best model to unlabeled data\n",
    "n_predictions = 10  # PARAMETER: Number of predictions to display\n",
    "best_model_name = test_results[0][0]\n",
    "best_model = next(model for name, model in optimized_models if name == best_model_name)\n",
    "X_unlabeled = df_unlabeled.drop(['class', 'txId'], axis=1)\n",
    "predictions = best_model.predict(X_unlabeled)\n",
    "df_prediction = pd.Series(predictions, name=\"prediction\")\n",
    "df_final = pd.concat([df_unlabeled[['txId']], df_prediction], axis=1)\n",
    "df_final = df_final.applymap(lambda x: 'Illicit' if x == '1' else 'Licit' if x == '2' else x)\n",
    "\n",
    "# Analyze prediction distribution\n",
    "class_counts = df_final['prediction'].value_counts()\n",
    "labeled_only = class_counts[class_counts.index != 'unknown']\n",
    "imbalance_ratio = labeled_only.max() / labeled_only.min() if len(labeled_only) >= 2 else 1.0\n",
    "\n",
    "# Plot distribution\n",
    "print(f\"\\nðŸ“ˆ Prediction Distribution:\")\n",
    "print(f\"Model used:\", best_model_name)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "class_counts.plot(kind='bar', ax=ax1, color=['lightblue', 'orange', 'lightcoral'])\n",
    "ax1.set_title('Class Counts')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "class_counts.plot(kind='pie', ax=ax2, autopct='%1.1f%%', colors=['lightblue', 'orange', 'lightcoral'])\n",
    "ax2.set_title('Class Distribution')\n",
    "ax2.set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display prediction samples and summary statistics\n",
    "print(f\"ðŸ“Š Prediction Summary:\")\n",
    "print(f\"  Total predictions: {len(df_final):,}\")\n",
    "print(f\"  Illicit transactions: {sum(df_final['prediction'] == 'Illicit'):,}\")\n",
    "print(f\"  Licit transactions: {sum(df_final['prediction'] == 'Licit'):,}\")\n",
    "print(f\"  Imbalance ratio: {imbalance_ratio:.1f}:1\")\n",
    "\n",
    "# Get sample transactions for analysis\n",
    "illicit_selector = df_final['prediction'] == 'Illicit'\n",
    "X_unlabeled_illicit = df_final[illicit_selector].head(100)\n",
    "print(f\"\\nðŸ”® Sample illicit transactions (showing {len(X_unlabeled_illicit)} of {sum(illicit_selector):,} total)\")\n",
    "display(X_unlabeled_illicit)\n",
    "\n",
    "licit_selector = df_final['prediction'] == 'Licit'\n",
    "X_unlabeled_licit = df_final[licit_selector].head(100)\n",
    "print(f\"\\nðŸ”® Sample licit transactions (showing {len(X_unlabeled_licit)} of {sum(licit_selector):,} total)\")\n",
    "display(X_unlabeled_licit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations\n",
    "\n",
    "Some considerations must be made before the conclusion:\n",
    "\n",
    "- Compressed data can increase training time but reduces dataset sizes without influencing the final result.\n",
    "\n",
    "- Models like Naive Bayes reached almost 0.6 in contrast to other models and were removed from training;  \n",
    "\n",
    "- Models like Logistic Regression also had poor performance and were removed from training, but they are used in some ensembles as default estimator models. \n",
    "\n",
    "**Future improvements to training:**\n",
    "\n",
    "- Models could be improved to have more ensemble combinations in this supervised machine learning approach, such as an XGBoostAdaBoost of the best model, or voting with the best three models;\n",
    "\n",
    "- The training could be more extensive in the number of training folds;\n",
    "\n",
    "- The training could use Optuna's approach to hyperparameter search, using Bayesian Optimization instead of random exhaustive search, which could reduce training time and increase model performance;\n",
    "\n",
    "- Instead of using a score function that is only applied in model validation procedures, a similar objective function could guide the training toward the most valuable metric, such as recall;  \n",
    "\n",
    "- The unsupervised approach could produce good or even better results because it would use much more data to identify patterns by using the complete dataset. Also, the labeled dataset could indicate which clusters could be labeled with the illicit class;\n",
    "\n",
    "- The training could use models more recommended for graph-type datasets, such as Graph Convolutional Networks (GCN), making use of the edge dataset to learn patterns with deeper transaction chains, not only direct neighbors.\n",
    "\n",
    "**Production readiness:**\n",
    "\n",
    "- This training was performed on a dataset curated for research purposes. There is no information about which features were used, so in order to have a production-ready model, a new dataset in the same format would need to be gathered and curated;\n",
    "\n",
    "- A final performance indicator would need to be established to consider the model ready for a production environment, by classifying real labeled current data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "#### Model Performance Summary\n",
    "\n",
    "This supervised learning approach successfully developed a high-performance KYT system achieving **88.49% performance** on cryptocurrency transaction risk classification. The **SVM (Support Vector Machine)** emerged as the champion model, demonstrating superior performance in distinguishing illicit from licit Bitcoin transactions.\n",
    "\n",
    "#### Key Technical Achievements\n",
    "\n",
    "- **Dimensionality Reduction**: PCA preprocessing reduced feature space from 166 to 59 dimensions while preserving 95% variance\n",
    "- **Algorithm Comparison**: Comprehensive evaluation of 10 ML algorithms with hyperparameter optimization via RandomizedSearchCV  \n",
    "- **Model Ranking**: SVM (88.49%) > KNN (86.87%) > GB (85.02%) demonstrated that ensemble and kernel methods excel in financial pattern recognition\n",
    "- **Pipeline Standardization**: StandardScaler + PCA + model architecture ensures consistent preprocessing across algorithms\n",
    "- **Model Persistence**: All trained models saved with compression for deployment scalability\n",
    "- **Performance Validation**: Stratified cross-validation ensures reliable performance on imbalanced financial data\n",
    "\n",
    "#### Real-World Impact\n",
    "\n",
    "The trained model successfully processed **157,205 unlabeled transactions**, identifying **12,675 potentially illicit transactions**, providing risk assessment capabilities for unknown dataâ€”essential for AML compliance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-analytics-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
