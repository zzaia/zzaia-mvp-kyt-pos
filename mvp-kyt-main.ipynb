{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVP Know Your Transaction (KYT) - Real-Time Transaction Risk Scoring Engine\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This notebook presents a comprehensive implementation of a Real-Time Transaction Risk Scoring Engine for Anti-Money Laundering (AML) compliance in cryptocurrency transactions. The project addresses the critical need for sub-second risk assessment of Bitcoin transactions by combining traditional AML indicators with blockchain-specific risk factors.\n",
    "\n",
    "### Domain Context: Financial AML for Transactions\n",
    "\n",
    "#### Core Domain Definition\n",
    "Anti-Money Laundering (AML) for transactions encompasses the comprehensive framework of laws, regulations, procedures, and technological solutions designed to prevent criminals from disguising illegally obtained funds as legitimate income through the global financial system. This domain includes detection, prevention, and reporting of money laundering, terrorist financing, tax evasion, market manipulation, and misuse of public funds.\n",
    "\n",
    "### Problem Definition: Real-Time Transaction Risk Classification Engine\n",
    "\n",
    "#### Problem Statement\n",
    "Develop a system that assigns risk classifications to cryptocurrency transactions in real-time, integrating traditional AML indicators with blockchain-specific risk factors including wallet clustering, transaction graph analysis, and counterparty reputation scoring.\n",
    "\n",
    "#### Technical Requirements\n",
    "- **Problem Type**: Classification \n",
    "- **Processing Speed**: Sub-second analysis for high-frequency transactions\n",
    "- **Difficulty Level**: High - requires complex multi-dimensional data processing\n",
    "- **Output Format**: Risk binary classification (illicit/licit)\n",
    "\n",
    "#### Data Landscape\n",
    "The system processes multiple data dimensions:\n",
    "- Transaction metadata (amounts, timestamps, fees)\n",
    "- Wallet addresses and clustering information\n",
    "- Transaction graph relationships and network topology\n",
    "- Counterparty databases and reputation scores\n",
    "- Sanctions lists and regulatory databases\n",
    "- Temporal patterns and behavioral baselines\n",
    "\n",
    "### References\n",
    "\n",
    "This notebook implementation is based on the comprehensive research and analysis conducted during the project development phase. The following reference documents were used in the composition of this initial description:\n",
    "\n",
    "- **Domain Research**: [current-domain.md](domains/current-domain.md) - Contains detailed market analysis, regulatory framework research, and commercial viability assessment for the Financial AML domain\n",
    "- **Problem Analysis**: [current-problem.md](problems/current-problem.md) - Provides comprehensive problem refinement, technical requirements analysis, and solution approach evaluation\n",
    "- **Dataset Evaluation**: [current-dataset.md](datasets/current-dataset.md) - Documents dataset selection criteria, suitability scoring, and detailed feature analysis for the Elliptic dataset\n",
    "- **Dataset Analysis & Preprocessing**: [dataset-analysis-and-preprocessing.ipynb](datasets/scripts/dataset-analysis-and-preprocessing.ipynb) - Comprehensive Jupyter notebook containing Elliptic dataset download, exploratory data analysis, feature engineering, preprocessing pipeline, and ML preparation steps\n",
    "\n",
    "These reference documents contain the foundational research that informed the technical approach, feature engineering strategy, and implementation decisions reflected in this notebook.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook serves as the primary entry point for the MVP KYT implementation, providing both technical implementation and business context for real-time cryptocurrency transaction risk assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "Comprehensive import of all required libraries for machine learning procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform, loguniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-processed datasets\n",
    "\n",
    "The pre-processing step reduced the dimensionality from 166 features to only 46."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from HDF5: (203769, 48) - All subsequent operations will use compressed data\n",
      "Loaded from HDF5: (46564, 48) - All subsequent operations will use compressed data\n",
      "Loaded from HDF5: (157205, 48) - All subsequent operations will use compressed data\n",
      "Loaded from HDF5: (234355, 2) - All subsequent operations will use compressed data\n",
      "\n",
      "📊 Dataset Summary:\n",
      "  - Features: 203,769 transactions × 46 features\n",
      "  - Labeled: 46,564 transactions\n",
      "  - Unlabeled: 157,205 transactions\n",
      "  - Edges: 234,355 transaction relationships\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The complete dataset already pre-processed \n",
    "df_complete = pd.read_hdf(\"./datasets/processed/df_complete.h5\", key=\"df_complete\")\n",
    "print(f\"Loaded from HDF5: {df_complete.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "# The filtered labeled dataset already pre-processed\n",
    "df_labeled = pd.read_hdf(\"./datasets/processed/df_labeled.h5\", key=\"df_labeled\")\n",
    "print(f\"Loaded from HDF5: {df_labeled.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "# The filtered unlabeled dataset already pre-processed\n",
    "df_unlabeled = pd.read_hdf(\"./datasets/processed/df_unlabeled.h5\", key=\"df_unlabeled\")\n",
    "print(f\"Loaded from HDF5: {df_unlabeled.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "# The edges dataset that maps relationships between transaction nodes\n",
    "df_edges = pd.read_hdf(\"./datasets/processed/df_edges.h5\", key=\"df_edges\")\n",
    "print(f\"Loaded from HDF5: {df_edges.shape} - All subsequent operations will use compressed data\")\n",
    "\n",
    "\n",
    "# Summary of all datasets\n",
    "print(f\"\\n📊 Dataset Summary:\")\n",
    "print(f\"  - Features: {df_complete.shape[0]:,} transactions × {df_complete.shape[1] -2} features\")\n",
    "print(f\"  - Labeled: {df_labeled.shape[0]:,} transactions\")\n",
    "print(f\"  - Unlabeled: {df_unlabeled.shape[0]:,} transactions\")\n",
    "print(f\"  - Edges: {df_edges.shape[0]:,} transaction relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Strategy\n",
    "\n",
    "Let's try three machine learning approaches with the data and compare than, each methodology will have it's winning model. \n",
    "\n",
    "1. Train models using the supervised methodology using only the labeled sub-dataset;\n",
    "2. Train models using the non-supervised approach using the complete dataset ignoring the edge dataset; **[FUTURE DEVELOPMENT]**\n",
    "3. Train models using the non-supervised approach using the complete dataset taking to account the relationship between those transactions, by using the edge dataset. **[FUTURE DEVELOPMENT]**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Train models using the supervised methodology\n",
    "\n",
    "Let`s prepare the dataset for training and validation\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some parameters\n",
    "np.random.seed(7)\n",
    "\n",
    "# Prepare data (df_labeled already loaded: 46,564 × 48)\n",
    "seed = 7 # random seed\n",
    "test_size = 0.20 # test set size\n",
    "X = df_labeled.drop(['class', 'txId'], axis=1)  # 46 features\n",
    "y = df_labeled['class']  # Binary target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size=test_size, shuffle=True, random_state=seed, stratify=y) # stratified holdout\n",
    "\n",
    "# Cross-validation setup\n",
    "n_splits = 2 # PARAMETER: number of folds\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define which models to use\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the individual models\n",
    "reg = ('LR', LogisticRegression())\n",
    "knn = ('KNN', KNeighborsClassifier())\n",
    "cart = ('CART', DecisionTreeClassifier())\n",
    "naive = ('NB', GaussianNB())\n",
    "svm = ('SVM', SVC())\n",
    "\n",
    "models = []\n",
    "models.append(reg)\n",
    "models.append(knn)\n",
    "models.append(cart)\n",
    "models.append(naive)\n",
    "models.append(svm)\n",
    "\n",
    "# Defining ensemble models\n",
    "bagging = ('Bag', BaggingClassifier())\n",
    "forest = ('RF', RandomForestClassifier())\n",
    "extra = ('ET', ExtraTreesClassifier())\n",
    "ada = ('Ada', AdaBoostClassifier())\n",
    "gradient = ('GB', GradientBoostingClassifier())\n",
    "voting = ('Voting', VotingClassifier(models))\n",
    "\n",
    "# Creating the pipelines\n",
    "pipelines = []\n",
    "\n",
    "# Defining the pipelines, for future experimentation \n",
    "pipelines.append(('LR', Pipeline([reg]))) \n",
    "pipelines.append(('KNN', Pipeline([knn])))\n",
    "pipelines.append(('CART', Pipeline([cart])))\n",
    "pipelines.append(('NB', Pipeline([naive])))\n",
    "pipelines.append(('SVM', Pipeline([svm])))\n",
    "#pipelines.append(('Bag', Pipeline([bagging])))\n",
    "#pipelines.append(('RF', Pipeline([forest])))\n",
    "#pipelines.append(('ET', Pipeline([extra])))\n",
    "#pipelines.append(('Ada', Pipeline([ada])))\n",
    "#pipelines.append(('GB', Pipeline([gradient])))\n",
    "#pipelines.append(('Vot', Pipeline([voting])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the parameter distributions for a random grid search\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter distributions for RandomizedSearchCV\n",
    "# Enhanced with log-uniform distributions and comprehensive documentation\n",
    "# Optimized for financial/cryptocurrency transaction risk classification\n",
    "\n",
    "param_distributions = {\n",
    "    'LR': {\n",
    "        # REGULARIZATION STRENGTH (C): Inverse regularization strength\n",
    "        # Lower values = stronger regularization = simpler model (prevent overfitting)\n",
    "        # Higher values = weaker regularization = more complex model\n",
    "        # Log-uniform for exponential search across orders of magnitude\n",
    "        # Critical for financial data: balance between model complexity and generalization\n",
    "        'LR__C': loguniform(1e-4, 1e2),\n",
    "\n",
    "        # OPTIMIZATION SOLVER: Algorithm for weight optimization\n",
    "        # 'lbfgs': Fast for small datasets, good convergence, handles L2/none penalty\n",
    "        # 'newton-cg': Robust for large datasets, handles L2/none penalty\n",
    "        # 'sag': Stochastic Average Gradient, fast for large datasets\n",
    "        # 'saga': Supports all penalties, good for sparse features (financial data)\n",
    "        # Removed 'liblinear': slower for datasets > 10K samples\n",
    "        'LR__solver': ['lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "\n",
    "        # REGULARIZATION TYPE: Controls feature selection and overfitting\n",
    "        # 'l2': Ridge regression, keeps all features, reduces coefficients\n",
    "        # 'none': No regularization, may overfit with many features\n",
    "        # Removed 'l1': Lasso causes issues with solver compatibility\n",
    "        # Financial context: L2 better for correlated transaction features\n",
    "        'LR__penalty': ['l2', 'none'],\n",
    "\n",
    "        # MAXIMUM ITERATIONS: Convergence limit for optimization\n",
    "        # Higher values ensure convergence but increase training time\n",
    "        # Financial data often needs more iterations due to class imbalance\n",
    "        # 2000+ recommended for 46K+ samples to avoid convergence warnings\n",
    "        'LR__max_iter': [1000, 2000, 5000],\n",
    "\n",
    "        # CONVERGENCE TOLERANCE: Stopping criteria precision\n",
    "        # Lower values = more precise convergence = longer training time\n",
    "        # Financial models need precise convergence for regulatory compliance\n",
    "        # 1e-6: High precision, 1e-4: Fast convergence\n",
    "        'LR__tol': loguniform(1e-6, 1e-3)\n",
    "    },\n",
    "\n",
    "    'KNN': {\n",
    "        # NUMBER OF NEIGHBORS: Core hyperparameter for KNN algorithm\n",
    "        # Lower values = more complex decision boundary = higher variance\n",
    "        # Higher values = smoother decision boundary = higher bias\n",
    "        # Financial context: 5-15 often optimal for transaction classification\n",
    "        # Odd numbers prevent ties in binary classification\n",
    "        'KNN__n_neighbors': randint(3, 21),\n",
    "\n",
    "        # WEIGHT FUNCTION: How neighbors influence prediction\n",
    "        # 'uniform': All neighbors weighted equally\n",
    "        # 'distance': Closer neighbors have higher influence\n",
    "        # Financial context: 'distance' often better for transaction patterns\n",
    "        'KNN__weights': ['uniform', 'distance'],\n",
    "\n",
    "        # DISTANCE METRIC: How to measure similarity between transactions\n",
    "        # 'euclidean': Standard L2 distance, good for continuous features\n",
    "        # 'manhattan': L1 distance, robust to outliers (good for financial data)\n",
    "        # 'minkowski': Generalization, controlled by 'p' parameter\n",
    "        'KNN__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "\n",
    "        # MINKOWSKI POWER: Only used when metric='minkowski'\n",
    "        # p=1: Manhattan distance, p=2: Euclidean distance\n",
    "        # Financial data: p=1 often better due to outlier robustness\n",
    "        'KNN__p': randint(1, 3)\n",
    "    },\n",
    "\n",
    "    'CART': {\n",
    "        # MAXIMUM TREE DEPTH: Primary overfitting control\n",
    "        # Lower values = simpler tree = less overfitting = higher bias\n",
    "        # Financial context: 5-15 often optimal for interpretability vs performance\n",
    "        # Too deep trees memorize transactions instead of learning patterns\n",
    "        'CART__max_depth': randint(3, 20),\n",
    "\n",
    "        # MINIMUM SAMPLES TO SPLIT: Prevents splitting on small sample sizes\n",
    "        # Higher values = more conservative splits = less overfitting\n",
    "        # Financial context: 10-50 good for 46K+ dataset to ensure robust splits\n",
    "        'CART__min_samples_split': randint(10, 50),\n",
    "\n",
    "        # MINIMUM SAMPLES PER LEAF: Ensures leaf nodes have sufficient samples\n",
    "        # Higher values = smoother predictions = less overfitting\n",
    "        # Critical for financial data: prevents decisions based on few transactions\n",
    "        'CART__min_samples_leaf': randint(5, 20),\n",
    "\n",
    "        # SPLIT QUALITY MEASURE: Criterion for evaluating split quality\n",
    "        # 'gini': Gini impurity, faster computation\n",
    "        # 'entropy': Information gain, potentially better separation\n",
    "        # Financial context: both work well, entropy slightly better for imbalanced data\n",
    "        'CART__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "\n",
    "    'NB': {\n",
    "        # VARIANCE SMOOTHING: Laplace smoothing for numerical stability\n",
    "        # Prevents zero probabilities when features have zero variance\n",
    "        # Log-uniform for exponential search across precision levels\n",
    "        # Financial context: 1e-9 to 1e-6 range good for PCA-transformed features\n",
    "        'NB__var_smoothing': loguniform(1e-12, 1e-6),\n",
    "\n",
    "        # CLASS PRIORS: Prior probabilities for each class\n",
    "        # None: Learn priors from training data (recommended)\n",
    "        # Custom priors could be set based on known illicit transaction rates\n",
    "        'NB__priors': [None]\n",
    "    },\n",
    "\n",
    "    'SVM': {\n",
    "        # REGULARIZATION PARAMETER: Trade-off between margin and misclassification\n",
    "        # Lower C = wider margin = more regularization = simpler model\n",
    "        # Higher C = narrower margin = less regularization = complex model\n",
    "        # Log-uniform critical for SVM: performance varies across orders of magnitude\n",
    "        # Financial context: Often needs tuning from 0.01 to 1000\n",
    "        'SVM__C': loguniform(1e-2, 1e3),\n",
    "\n",
    "        # KERNEL FUNCTION: Maps features to higher-dimensional space\n",
    "        # 'rbf': Radial basis function, good for non-linear financial patterns\n",
    "        # 'poly': Polynomial kernel, can capture feature interactions\n",
    "        # 'sigmoid': Tanh kernel, neural network-like behavior\n",
    "        # Removed 'linear': redundant with LogisticRegression for PCA features\n",
    "        'SVM__kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "\n",
    "        # KERNEL COEFFICIENT: Controls kernel shape and influence\n",
    "        # 'scale': 1/(n_features * X.var()) - good default for normalized data\n",
    "        # 'auto': 1/n_features - simpler scaling\n",
    "        # Log-uniform range would be loguniform(1e-6, 1e-1) for custom values\n",
    "        'SVM__gamma': ['scale', 'auto']\n",
    "    },\n",
    "\n",
    "    'RF': {\n",
    "        # NUMBER OF TREES: Primary performance vs speed trade-off\n",
    "        # More trees = better performance = longer training/prediction time\n",
    "        # Financial context: 100-500 often optimal, diminishing returns after 300\n",
    "        # Real-time KYT systems need to balance accuracy with inference speed\n",
    "        'RF__n_estimators': randint(100, 500),\n",
    "\n",
    "        # MAXIMUM TREE DEPTH: Individual tree complexity control\n",
    "        # None = trees grow until pure leaves (may overfit)\n",
    "        # Specific values prevent overfitting in ensemble\n",
    "        # Financial context: 10-25 good for transaction complexity\n",
    "        'RF__max_depth': randint(10, 25),\n",
    "\n",
    "        # MINIMUM SAMPLES TO SPLIT: Conservative splitting threshold\n",
    "        # Higher values = more robust trees = better generalization\n",
    "        # Financial data: 5-20 good for 46K+ samples\n",
    "        'RF__min_samples_split': randint(5, 20),\n",
    "\n",
    "        # MINIMUM SAMPLES PER LEAF: Leaf node size constraint\n",
    "        # Prevents overfitting to individual transactions\n",
    "        # Financial context: 2-10 ensures meaningful leaf nodes\n",
    "        'RF__min_samples_leaf': randint(2, 10),\n",
    "\n",
    "        # FEATURE SUBSET SIZE: Number of features per tree split\n",
    "        # 'sqrt': sqrt(n_features) ≈ 7 features for 46 total\n",
    "        # 'log2': log2(n_features) ≈ 6 features for 46 total\n",
    "        # None: Use all features (may reduce diversity)\n",
    "        # Financial context: 'sqrt' often optimal for transaction features\n",
    "        'RF__max_features': ['sqrt', 'log2', None],\n",
    "\n",
    "        # BOOTSTRAP SAMPLING: Sample replacement for tree training\n",
    "        # True: Standard random forest with replacement sampling\n",
    "        # False: Use entire dataset for each tree (less diversity)\n",
    "        # Financial context: True recommended for better generalization\n",
    "        'RF__bootstrap': [True, False]\n",
    "    },\n",
    "\n",
    "    'ET': {\n",
    "        # Extra Trees: Similar to Random Forest but with random splits\n",
    "        # Generally faster training, sometimes better performance\n",
    "        # Parameters similar to Random Forest but more aggressive randomization\n",
    "\n",
    "        'ET__n_estimators': randint(100, 500),          # Number of trees in ensemble\n",
    "        'ET__max_depth': randint(10, 25),               # Maximum depth of trees\n",
    "        'ET__min_samples_split': randint(5, 20),        # Min samples to split node\n",
    "        'ET__min_samples_leaf': randint(2, 10),         # Min samples at leaf\n",
    "        'ET__max_features': ['sqrt', 'log2', None],     # Random feature subset size\n",
    "        'ET__bootstrap': [True, False]                  # Bootstrap sampling toggle\n",
    "    },\n",
    "\n",
    "    'GB': {\n",
    "        # BOOSTING STAGES: Number of sequential weak learners\n",
    "        # More stages = better performance = higher overfitting risk\n",
    "        # Financial context: 100-300 often optimal, early stopping recommended\n",
    "        'GB__n_estimators': randint(100, 300),\n",
    "\n",
    "        # LEARNING RATE: Step size shrinkage for gradient updates\n",
    "        # Lower rates = more conservative learning = need more estimators\n",
    "        # Higher rates = aggressive learning = risk of overshooting optimum\n",
    "        # Log-uniform for exponential search: 0.01-0.3 typical range\n",
    "        # Financial context: 0.05-0.15 often optimal for stability\n",
    "        'GB__learning_rate': loguniform(1e-2, 3e-1),\n",
    "\n",
    "        # INDIVIDUAL TREE DEPTH: Weak learner complexity\n",
    "        # Gradient boosting uses shallow trees (stumps to 8 levels)\n",
    "        # Higher depth = stronger individual learners = risk of overfitting\n",
    "        # Financial context: 3-8 optimal for transaction patterns\n",
    "        'GB__max_depth': randint(3, 8),\n",
    "\n",
    "        # SUBSAMPLE FRACTION: Stochastic gradient boosting\n",
    "        # < 1.0 = use random subset of samples for each tree\n",
    "        # Reduces overfitting and improves generalization\n",
    "        # Financial context: 0.7-0.9 good for large transaction datasets\n",
    "        'GB__subsample': uniform(0.7, 0.2)  # 0.7 to 0.9 range\n",
    "    },\n",
    "\n",
    "    'Ada': {\n",
    "        # ADAPTIVE BOOSTING: Sequential weak learner weighting\n",
    "        # Focuses on previously misclassified transactions\n",
    "\n",
    "        # NUMBER OF WEAK LEARNERS: Maximum boosting rounds\n",
    "        # AdaBoost often needs fewer estimators than Gradient Boosting\n",
    "        # Financial context: 50-200 sufficient for most transaction patterns\n",
    "        'Ada__n_estimators': randint(50, 200),\n",
    "\n",
    "        # LEARNING RATE: Weight applied to each weak classifier\n",
    "        # Lower rates = more conservative = better generalization\n",
    "        # Higher rates = aggressive = faster convergence but overfitting risk\n",
    "        # Financial context: 0.5-1.5 range for transaction classification\n",
    "        'Ada__learning_rate': uniform(0.5, 1.0),  # 0.5 to 1.5 range\n",
    "\n",
    "        # BOOSTING ALGORITHM: AdaBoost variant\n",
    "        # 'SAMME': Discrete AdaBoost, works with any base classifier\n",
    "        # 'SAMME.R': Real AdaBoost, requires probability estimates\n",
    "        # Financial context: SAMME.R often faster and more accurate\n",
    "        'Ada__algorithm': ['SAMME', 'SAMME.R']\n",
    "    },\n",
    "\n",
    "    'Bag': {\n",
    "        # BOOTSTRAP AGGREGATING: Parallel ensemble method\n",
    "        # Reduces overfitting through averaging multiple models\n",
    "\n",
    "        'Bag__n_estimators': randint(50, 200),          # Number of base estimators\n",
    "\n",
    "        # SAMPLE FRACTION: Proportion of dataset for each estimator\n",
    "        # Lower values = more diversity = better generalization\n",
    "        # Higher values = more stable individual models\n",
    "        # Financial context: 0.6-0.9 good for transaction data diversity\n",
    "        'Bag__max_samples': uniform(0.6, 0.3),  # 0.6 to 0.9 range\n",
    "\n",
    "        # FEATURE FRACTION: Proportion of features for each estimator\n",
    "        # Creates feature diversity in ensemble\n",
    "        # Financial context: 0.7-1.0 to maintain transaction pattern integrity\n",
    "        'Bag__max_features': uniform(0.7, 0.3)   # 0.7 to 1.0 range\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute the training phase using the random grid search with cross validation and rank the best models by accuracy.\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Training Models with RandomizedSearchCV Optimization...\n",
      "Training 5 models: Basic + Ensemble methods\n",
      "------------------------------------------------------------\n",
      "Training LR... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m param_distributions \u001b[38;5;129;01mand\u001b[39;00m param_distributions[name]:\n\u001b[32m     18\u001b[39m     random_search = RandomizedSearchCV(\n\u001b[32m     19\u001b[39m         estimator=model,\n\u001b[32m     20\u001b[39m         param_distributions=param_distributions[name],\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m         n_jobs=n_jobs\n\u001b[32m     27\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     best_model = random_search.best_estimator_\n\u001b[32m     30\u001b[39m     best_score = random_search.best_score_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "n_iter = 5  # PARAMETER: Number of parameter combinations to try\n",
    "scoring = 'accuracy' # PARAMETER: Scoring metric\n",
    "n_jobs = -1  # PARAMETER: Use all available cores\n",
    "verbosity = 0  # PARAMETER: Verbosity level\n",
    "\n",
    "optimized_models = []\n",
    "results = []\n",
    "\n",
    "print(\"🔍 Training Models with RandomizedSearchCV Optimization...\")\n",
    "print(f\"Training {len(pipelines)} models: Basic + Ensemble methods\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, model in pipelines:\n",
    "    print(f\"Training {name}...\", end=\" \")\n",
    "    # Use RandomizedSearchCV for models with parameters definitions\n",
    "    if name in param_distributions and param_distributions[name]:\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=model,\n",
    "            param_distributions=param_distributions[name],\n",
    "            n_iter=n_iter,\n",
    "            cv=cv,\n",
    "            verbose=verbosity,\n",
    "            scoring=scoring,\n",
    "            random_state=seed,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "        random_search.fit(X_train, y_train)\n",
    "        best_model = random_search.best_estimator_\n",
    "        best_score = random_search.best_score_\n",
    "        std_score = random_search.cv_results_['std_test_score'][random_search.best_index_]\n",
    "        \n",
    "        print(f\"✅ {best_score:.4f} (±{std_score:.4f})\")\n",
    "    else:\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring)\n",
    "        best_model = model\n",
    "        best_score = cv_results.mean()\n",
    "        std_score = cv_results.std()\n",
    "        \n",
    "        print(f\"✅ {best_score:.4f} (±{std_score:.4f})\")\n",
    "    \n",
    "    optimized_models.append((name, best_model))\n",
    "    results.append(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save all models\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved 5 models: ['LR', 'KNN', 'CART', 'NB', 'SVM']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Try to save models from training\n",
    "    os.makedirs(\"./models\", exist_ok=True)\n",
    "    for name, model in optimized_models:\n",
    "        joblib.dump(model, f\"./models/{name}.pkl\", compress=True)\n",
    "    print(f\"💾 Saved {len(optimized_models)} models: {[name for name, _ in optimized_models]}\")\n",
    "except NameError:\n",
    "    # Load models if optimized_models doesn't exist\n",
    "    optimized_models = []\n",
    "    if os.path.exists(\"./models\"):\n",
    "        for file in os.listdir(\"./models\"):\n",
    "            if file.endswith('.pkl'):\n",
    "                name = file.replace('.pkl', '')\n",
    "                model = joblib.load(f\"./models/{file}\")\n",
    "                optimized_models.append((name, model))\n",
    "        print(f\"📁 Loaded {len(optimized_models)} models: {[name for name, _ in optimized_models]}\")\n",
    "    else:\n",
    "        print(\"❌ No models found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate and select the best models\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Test Accuracy = 0.9316\n",
      "KNN: Test Accuracy = 0.9719\n",
      "CART: Test Accuracy = 0.9677\n",
      "NB: Test Accuracy = 0.6472\n",
      "SVM: Test Accuracy = 0.9794\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (5).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m ax = fig.add_subplot(\u001b[32m111\u001b[39m) \n\u001b[32m     13\u001b[39m plt.boxplot([accuracy \u001b[38;5;28;01mfor\u001b[39;00m _, _, accuracy \u001b[38;5;129;01min\u001b[39;00m test_results]) \n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_xticklabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_results\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotation\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m90\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m plt.show()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Sort by test accuracy and get top 3\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages/matplotlib/axes/_base.py:74\u001b[39m, in \u001b[36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv-analytics-py312/lib/python3.12/site-packages/matplotlib/axis.py:2106\u001b[39m, in \u001b[36mAxis.set_ticklabels\u001b[39m\u001b[34m(self, labels, minor, fontdict, **kwargs)\u001b[39m\n\u001b[32m   2102\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker.FixedLocator):\n\u001b[32m   2103\u001b[39m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[32m   2104\u001b[39m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[32m   2105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator.locs) != \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) != \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2106\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2107\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe number of FixedLocator locations\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2108\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator.locs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m), usually from a call to\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2109\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m set_ticks, does not match\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2110\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2111\u001b[39m     tickd = {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator.locs, labels)}\n\u001b[32m   2112\u001b[39m     func = functools.partial(\u001b[38;5;28mself\u001b[39m._format_with_dict, tickd)\n",
      "\u001b[31mValueError\u001b[39m: The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (5)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select best 3 models based on test accuracy\n",
    "test_results = []\n",
    "for name, model in optimized_models:\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_results.append((name, model, accuracy))\n",
    "    print(f\"{name}: Test Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Comparison Boxplot\n",
    "fig = plt.figure(figsize=(25,6))\n",
    "fig.suptitle('Models Comparison') \n",
    "ax = fig.add_subplot(111) \n",
    "plt.boxplot([accuracy for _, _, accuracy in test_results]) \n",
    "ax.set_xticklabels([name for name, _, _ in test_results], rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Sort by test accuracy and get top 3\n",
    "test_results.sort(key=lambda x: x[2], reverse=True)\n",
    "best_optimized_models = [(name, model) for name, model, acc in test_results[:3]]\n",
    "\n",
    "print(f\"\\n🏆 Final top 3 models: {[name for name, _ in best_optimized_models]}\")\n",
    "print(f\"📊 Test accuracies: {[f'{acc:.4f}' for _, _, acc in test_results[:3]]}\")\n",
    "\n",
    "# Test set summary\n",
    "print(f\"\\n🧪 Test set: {len(X_test)} samples, {X_test.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let`s apply the model into unknown data\n",
    "\n",
    "[Description]\n",
    "[Whys]\n",
    "[What]\n",
    "[When]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '2', '2', ..., '2', '2', '2'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 Predictions on 157205 unlabeled transactions\n",
      "Risk scores range: 0.000 - 1.000\n"
     ]
    }
   ],
   "source": [
    "# Apply best model to unlabeled data\n",
    "best_model = best_optimized_models[0][1]  # Champion model\n",
    "X_unlabeled = df_unlabeled.drop(['class', 'txId'], axis=1)\n",
    "\n",
    "predictions = best_model.predict(X_unlabeled)\n",
    "probabilities = best_model.predict_proba(X_unlabeled)[:, 1]\n",
    "display(predictions)\n",
    "print(f\"🔮 Predictions on {len(X_unlabeled)} unlabeled transactions\")\n",
    "#print(f\"Illicit predictions: {sum(predictions)} ({sum(predictions)/len(predictions)*101:.1f}%)\")\n",
    "print(f\"Risk scores range: {probabilities.min():.3f} - {probabilities.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train models using the non-supervised approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train models using the non-supervised approach using the edge dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-analytics-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
